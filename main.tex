\documentclass[review,creen,acmsmall]{acmart}
%\settopmatter{printfolios=false,printccs=false,printacmref=false}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}   %% For author/year citations
\usepackage{listings,multirow,wrapfig,xspace,paralist}
\usepackage{xcolor,tikz,graphicx, pifont}
\usetikzlibrary{positioning,automata,fit,shapes.geometric,backgrounds,calc}

\newcommand{\authorcomment}[3]{\xspace\textcolor{#1}{{\bf #2} #3}\xspace}
%%\newcommand{\authorcomment}[3]{}
% For author notes:
\newcommand{\AG}[1]{\authorcomment{orange}{AG}{#1}}
\newcommand{\JJ}[1]{\authorcomment{green}{JJ}{#1}}
\newcommand{\SK}[1]{\authorcomment{yellow}{SK}{#1}}
\newcommand{\OF}[1]{\authorcomment{magenta}{OF}{#1}}
\newcommand{\isit}[1]{\authorcomment{cyan}{Check}{#1}}
\newcommand{\todo}[1]{\authorcomment{red}{TODO}{#1}}
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}
\newcommand{\cmark}{\textcolor{green}{\ding{51}}}
\newcommand{\rmark}{\textcolor{blue}{\ding{108}}}

\newcommand{\always}{\emph{Always}\xspace}
\newcommand{\sometimes}{\emph{Sometimes}\xspace}
\newcommand{\sometimesStar}{\emph{Sometimes*}\xspace}
\newcommand{\never}{\emph{Never}\xspace}
\newcommand{\neverStar}{\emph{Never*}\xspace}
\newcommand{\rdyn}{{\sf R-dyntrace}\xspace}
\newcommand{\instr}{{\sf InstrumentR}\xspace}

\definecolor{LightGray}{RGB}{247, 247, 247}
\definecolor{Gray}{rgb}{.3,.3,.3}
\definecolor{DarkGray}{rgb}{.5,.5,.5}
\lstdefinelanguage{smalleR} {
  morekeywords={
    for,
    if,
    else,
    function
  },
  sensitive=true, % keywords are not case-sensitive
  morecomment=[l]{\#}, % l is for line comment
  morestring=[b]{"} % defines that strings are enclosed in double quotes
}
\lstset{
  language={smalleR},
  columns=flexible,
  captionpos=b,
  frame=single,
  framerule=0pt,
  tabsize=2,
  belowskip=0pt,
  basicstyle=\small\ttfamily,
  backgroundcolor=\color{LightGray},
  emphstyle=\sffamily,
  keywordstyle=\bfseries,
  commentstyle=\color{Gray}\em,
  stringstyle=\color{Gray},
  alsoletter={., _, $},
  breaklines=true}

\newcommand{\code}[1]{\lstinline |#1|\xspace}
\renewcommand{\c}[1]{\lstinline |#1|\xspace}
\newcommand{\strictr}{{\sf StrictR}\xspace}
\newcommand{\lazr}{{\sf LazR}\xspace}
\newcommand{\Rsh}{{\sf\v R}\xspace}
\newcommand{\eg}{\emph{e.g.},\xspace}
\newcommand{\ie}{\emph{i.e.},\xspace}
\newcommand{\config}[1]{configuration \#{#1}}
\newcommand{\cconfig}[1]{Configuration \#{#1}}
\input{macros.tex}
\include{results}
\setcopyright{rightsretained}
\acmPrice{}
\acmDOI{10.1145/3360579}
\acmYear{2021}
\copyrightyear{2021}
\acmJournal{PACMPL}
\acmVolume{3}
\acmNumber{OOPSLA}
\acmArticle{153}
\acmMonth{10}
\begin{document}
\title{Promises Are Made To Be Broken}
\subtitle{Migrating R to Strict Semantics}

\author{Aviral Goel}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Ječmen}\affiliation{\institution{Czech Technical University}\country{Czechia}}
\author{Sebastián Krynski}\affiliation{\institution{Czech Technical University}\country{Czechia}}
\author{Olivier Flückiger}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Vitek}\affiliation{\institution{Czech Technical University and Northeastern University}\country{USA}}
\authorsaddresses{}
\renewcommand{\shortauthors}{Goel, et al.}

\begin{abstract}
  Function calls in the R language do not evaluate their arguments, these are
  passed to the callee as suspended computations and evaluated if needed. After
  25 years of experience with the language, there are very few cases where
  programmers leverage delayed evaluation intentionally and laziness comes at a
  price in performance and complexity. This paper explores how to evolve the
  semantics of a lazy language towards strictness by default and laziness on
  demand. To provide a migration path, it is necessary to provide tooling for
  developers to migrate libraries without introducing errors. This paper reports
  on a dynamic analysis that infers strictness signatures for functions to
  capture both intentional and accidental laziness. Over 99\% of the inferred
  signatures were correct when tested against clients of the libraries.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002944.10011123.10010912</concept_id>
<concept_desc>General and reference~Empirical studies</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011050.10010517</concept_id>
<concept_desc>Software and its engineering~Scripting languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011039.10011311</concept_id>
<concept_desc>Software and its engineering~Semantics</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{General and reference~Empirical studies}
\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[500]{Software and its engineering~Scripting languages}
\ccsdesc[300]{Software and its engineering~Semantics}

\keywords{R language, delayed or lazy evaluation}

\maketitle
\section{Introduction}

The R programming language is widely used in data science. Yet many of users are
unaware that function calls have lazy semantics: arguments are suspended
computations that are evaluated if and when they are needed. \citet{oopsla19b}
provided a thorough observational study of R packages. Most packages are written
without reliance on laziness with the exception of meta-programming. This paper
argues that laziness should be the exception in R. We propose to migrate R
programs to an \emph{eager by default, lazy on demand} semantics. We focus on
the question whether on can switch the semantics of a language without causing
undue breakage in legacy code that is in daily use. Even if programmers do not
avail themselves of laziness, their code may accidentally depends on it.

\paragraph{The case for strictness.} Laziness is error-prone, inconsistent,
and costly! At least when combined with side-effects in a language without type
annotations it is. When a function with multiple evaluation orders is provided
effectful arguments, their effects can be ordered randomly. Functional languages
prevent this by controlling effects from their type system. While R users do not
have types, they often force evaluation at function boundaries. R's laziness is
inconsistent as there are points where evaluation is arbitrarily forced, \eg the
right-hand side of assignments and function returns. Furthermore,
object-oriented multiple dispatch evaluates arguments eagerly to obtain their
class. The costs of laziness comes from having to box each argument in data
structure that must be allocated and freed, and the limits this boxing puts on
compiler optimizations.

\paragraph{The case for laziness.} The success of a programming language
comes down to the strength of its ecosystem. With tens of millions of lines of
library code, any change risks breaking something. Preserving the status quo is
a pragmatic choice to protect an ecosystem. There is also a genuine need for
lazy evaluation: it is the building block of R's meta-programming facilities.
Unevaluated arguments can be coerced back to their source code, that code can be
modified and evaluated in an environment of the programmer's choice.
Meta-programming is used for language extension and to create embedded
domain-specific languages. While one could imagine using macros instead, the
number of libraries that would have to be refactored would be significant.

\paragraph{A pragmatic path forward.} How does on migrate an entire ecosystem?
A viable migration path must abide by four tenets: (1) minimal legacy code
changes, (2) semi-automated migration, (3) testable outcomes, and (4) measurable
benefits. We envision a migration path with the following characteristics.
Changes to legacy code are avoided by non-invasive extensions to the language's
syntax and semantics and limited to library functions that need a lazy
semantics. Strictness signatures are inferred from the tests associated to every
R package. For popular libraries, client code is used as an oracle to check the
correctness of inferred signatures. Performance and memory footprint are
improved by compiler optimizations that leverage the new semantics. This paper
aims to evaluate components of this migration

\newcommand{\rshstrict}{{\sf {\v R}$_{\mathsf s}$ }} %% SK added extra space at the end
\newcommand{\brshstrict}{{\bf {\v R}$_{\mathbf s}$}}

\begin{itemize}[---]
\item {\bf StrictR:} a prototype R interpreter with strict by default
  semantics; only functions that demand lazy evaluation need to be annotated.
\item {\bf LazR:} a scalable infrastructure for inferring strictness annotations
  for function arguments by dynamic program analysis.
\item {\bf \brshstrict:} an optimizing just-in-time compiler for R modified to
  take advantage of a strict by default semantics.
\end{itemize}

We conduct several experiments that aim to answer the question whether such a
semi-automated path is viable. Specifically, it should be the case that change
to the code are small, that inference is accurate, and that there are
performance improvements.

The paper reports on two experiments. First, we obtain the most widely used
packages in the R ecosystem and, with \lazr, leverage their regression tests to
infer strictness signatures. Since \strictr can load signatures from external
files, no changes to code are required. We then use clients of those packages to
test the accuracy of the inference results. Only \robustnesResult of the
signatures cause \strictr programs to exhibit observable differences from the
reference semantics. Our second experiment is independent from the first. We
take a suite of small computational tasks, manually annotate them for maximal
strictness, and run the benchmarks in strict and lazy modes using \rshstrict. We
observe speedups ranging from \speedupRshStrictMin to \speedupRshStrictMax for
the strict version.

Our conclusions are that the approach is viable as user-visible changes are
small and the inference gives promising results. For community review we intend
to further reduce the error rate by improving the precision of our analysis and
using all available clients to infer signatures rather than only the tests
bundled with a package. The performance numbers should be viewed as a limit
study as the baseline is a compiler that already performs aggressive
optimizations. We have not evaluated the benefits of \strictr on the bytecode
compiler used today. It is conceivable that the relative speedups could be more
impressive than in our native compiler, but in the long run we expect users
to move away from bytecode execution.

\paragraph{Availability.} Our work is available from:
    URL/of/artifact/goes/here

\section{Background}\label{sec:background}

This section sets the stage by introducing related work and giving a brief
overview of R.

\subsection{Related Work}

There are three clusters of related results: research on adding and removing
laziness in functional languages, research on the R language, and approaches to
language migration.

\paragraph{Call by need}  Functional languages with
a call by need evaluation strategy must contend with memory pressure and
associated performance issues due to allocation of a substantial number of
thunks (suspended computations)~\cite{transformopt,stricteffective,opteval}. The
Glasgow Haskell Compiler performs a strictness analysis pass to identify
arguments that can be evaluated eagerly. While most programs benefit from such a
transformation, due to its conservative nature, this pass misses some
opportunities for optimizations. To recover performance, programmers can
manually insert strictness annotations to control evaluation; identifying where
to put them, however, can be challenging. \citet{autobahn} proposed Autobahn, a
tool that automatically infers strictness annotations using a genetic algorithm.
The approach relies on dynamic analysis, which can be more precise than static
analysis but does not guarantee termination on all inputs. As the annotations
%%% TODO CHECK IF THE ABOVE IS RIGHT (says Jan)
are based on a heuristic, developers must manually validate their soundness. The
authors report an average 8.5\% speedup (with a maximum speedup of 89\%).
\citet{lazyprof} solve the complementary problem of suggesting laziness
annotations for call-by-value $\lambda$~calculus using dynamic analysis. They
introduce the notion of laziness potential, a predictor of the benefit obtained
by making an expression lazy. They use this as a guide to insert laziness
annotations. They demonstrate benefits on Racket implementations of Okasaki's
purely functional data structures~\cite{oka95}, monadic parser combinators, and
an AI game. Our work is similar to Autobahn in that we infer annotations
dynamically and we do not guarantee soundness. We depart from Autobahn in that
we use dynamic analysis of execution traces to determine strictness.
Furthermore, we must deal with side-effects and reflective operations which adds
extra complexity to our inference algorithm.

\paragraph{The R language} \citet{oopsla19b} investigated the design and use of
laziness in R. They provide a detailed account of the language's evaluation
strategy with a small-step operational semantics and an empirical evaluation of
laziness in 16,707 packages. Their study shows that most of the R code is
written without reliance on, or awareness of, laziness. Out of 388K functions,
83\% evaluate all of their arguments in a single order across all calls. The
authors found that programmers sometimes force evaluation of arguments at the
beginning of a function to protect their code from non-deterministic effects,
this is done by adding calls to \c{force} to every argument. Only a single
instance of a lazy data structure could be found in all the programs the author
inspected. The main \emph{raison d'\^etre} for delayed evaluation seems to be
meta-programming which requires delayed arguments that can be manipulated
symbolically. In that work, a function was deemed to be strict if it had a
single evaluation order for its arguments. Our approach is inspired by that
work, but we do not require a single evaluation order for a function, instead,
we choose to look at clients and declare a parameter lazy if some clients call
the function with effectful arguments. \citet{oopsla20b} empirically inferred
{type} signatures for functions by observing the type of arguments and return
values. These signatures were validated by inserting type checking code and
monitoring failures on client programs. This approach inspired our strictness
inference, however, types are easier to check than strictness. Types are checked
by validating that if an argument is evaluated it has the expected type. For
strictness, we have to worry about the interplay of side-effects and changes to
the order of evaluation of arguments.

\paragraph{Language migration} Changing a language with a large codebase
is challenging. No migration has been more fraught than that of Python. Python 3
was released in 2008 with many changes that broke backward compatibility and no
automated upgrade path. \citet{Agg15} attempted to use statistical machine
learning to convert Python 2 to 3. \citet{Pra20} described a tool for
discovering types in Python programs as a combination of probabilistic type
prediction and search-based refinement. Migration was also studied in the
context of Java libraries~\cite{Xu19}, Android apps~\cite{Orso20} and C++
applications~\cite{OB20}. A more successful experience is the migration from PHP
to Hack at Facebook. The key to success was a close feedback loop between
language changes and their impact on the ecosystem at large. As all Hack users
share an employer and a source code repository, it was possible to test changes
and develop tools targeted at relevant usage patterns.\footnote{Private
  communication with the developers of Hack.} One last relevant thread of work
is the migratory typing of \citet{matthias06} where a gradual type system is
added to a variant of the Scheme programming language to enable gradual
migration from untyped to typed code.

\subsection{Laziness and the R Language}

The R language is widely used in data science. R is a vectorized, dynamic, lazy,
functional and object-oriented programming language~\cite{ecoop12}, designed to
be easy to learn by non-programmers and to enable rapid development of new
statistical methods. The language was created in 1993 by~\citet{R96} as a
successor to an earlier language for statistics named S~\cite{S88}.

\paragraph{Functions}
In R every linguistic construct is desugared to a function call, even control
flow statements, assignments, and bracketing. Furthermore, all functions can be
redefined. This makes R both flexible and challenging to compile. A function
definition can include default expressions for parameters, these can refer to
other parameters. R functions are higher-order. The following snippet declares a
function \c f which takes a variable number of arguments, whose parameters
\c x and \c y, if missing, have default expressions \c y and
\c{3*x}, and which are only evaluated when needed. The function returns a
closure.

\begin{lstlisting}
 f <- function(x=y,...,y=3*x) { function(z) x+y+z }
\end{lstlisting}


This function can be called with a single argument matching \c x, as in
\c{f(3)}, with named arguments, as in \c{f(y=4,x=2)}, with a variable
number of arguments, for example \c{f(1,2,3,4,y=5)}, multiple arguments
captured by \c{...}, or with no arguments at all, \c{f()}, which creates a
cyclic dependency and errors out when the returned function is used. Some
functions are written to behave differently in the presence of missing
arguments. To this end the \c{missing(x)} built-in can be used to check if
parameter \c{x} was provided at the call site or not, even if it was later
substituted by a default value. A vararg parameter, written \c{...}, accepts
an arbitrary number of arguments, including missing arguments. A vararg can be
materialized into a list with \c{list(...)}. Most frequently varargs are
forwarded to a called function. This enables the function to expose its callee's
interface to the callers without listing the callee's parameters and their
default values.

\paragraph{Reflection}
R supports meta-programming. The \c{substitute(exp,env)} function yields the
parse tree of the expression \c{exp} after performing substitutions defined
by the bindings in \c{env}. Consider the following call that substitutes 1
for \c a and returns a value of type \c{expression}.

\begin{lstlisting}
 > substitute(expression(a + b), list(a = 1))
 expression(1 + b)
\end{lstlisting}

R allows programmatic manipulation of parse trees, which are themselves
first-class objects. They are evaluated using the \c{eval(exp,env)} function.
In R, the local scope of a closure is a first-class mutable map. Code can always
access its local environment, but it is also possible to reflectively extract
the environments of any function currently on the call stack.

\paragraph{Effects} Logically function arguments are passed by copy to
facilitate equational reasoning, the implementation optimizes this with a simple
copy-on-write of aliased values. While R strives to be functional, it has
imperative features such as assignment to local variables \c{<-}, assignment
to variables in an enclosing scope \c{<<-}, and assignment in a
programmatically chosen scope \c{assign()}. R supports non-local returns
either through exceptions or by delayed evaluation of a \c{return} statement.
Of course, there are all sorts of external effects and no monads.

\paragraph{Delayed Evaluation}
The combination of side effects, frequent interaction with C, and absence of
types has pushed R to be more eager than other lazy languages. Strictly
speaking, R is not lazy as it evaluates some arguments that it does not need to.
Let us review its design. Arguments to a function are bundled into a thunk
called a \emph{promise}. Logically, a promise combines an expression's code, its
environment, and its value. To access the value of a promise, one must
\emph{force} it. Forcing a promise triggers evaluation and the computed value is
captured for future reference. The following snippet defines a function that
takes an argument \c x and returns \c{x+x}. When called with an argument
that has the side effect of printing to the console, the side effect is
performed only once, the second access to the promise uses the cached result.

\begin{lstlisting}
 > f <- function(x) x+x
 > f( {print("Hi!");2} )
 "Hi!"
 4
\end{lstlisting}


A promise associated to the default value of a parameter has access to all
variables in scope, including other parameters. Promises cannot be forced
recursively, if this were to happen the R interpreter terminates execution of
the expression. Promises are mostly encapsulated and hidden from user code. R
only provides a small interface for operating on them:
\begin{itemize}
\item[] {\hskip -1em \bf\small\c{delayedAssign(x,exp,env,aenv)}}: creates a
  promise with body \c{exp} and binds it to variable \c x (here \c x is
  a symbol) in the environment \c{aenv}, evaluation of the promise will take
  place in environment \c{env}.
\item[] {\hskip -1em \bf\small\c{substitute(e,env)}}: substitutes variables
  in \c e with their values found in environment \c{env}, returns an
  \c{expression}.
\item[] {\hskip -1em \bf\small\c{force(x)}}: forces evaluation of its
  argument. This replaces a common programming idiom, \c{x<-x}, which forces
  \c x by assigning it to itself.
\item[] {\hskip -1em \bf\small\c{forceAndCall(n,f,...)}}: calls \c{f} with
  the arguments specified in the varargs, of which the first \c{n} are forced
  before the call.
\end{itemize}


There are implicit \c{force} call on values returned by a function and on the
right hand side of assignment. In addition, many core functions are strict. R
code can include extensions written in C, these are able to freely access and
mutate the expression stored in a promise, as well as the memoized result of
promises. Legacy C code, such as mathematical functions, typically expects
unwrapped values and not promises. While R does not provide built-in lazy data
structures, they can be encoded. For instance, the 'trick' to return an
unevaluated promise from a function is to wrap that promise in a newly created
environment.

\section{StrictR: An R Interpreter with Strictness Signatures}\label{sec:strictr}

\strictr is a prototype implementation of GNU R with a strict-by-default
semantics and strictness signatures to specify which arguments should remain
lazy. Our implementation is experimental in the sense that it is not looking at
performance, instead its purpose is to allow us to experiment with the semantics
of the language. The implementation uses source-to-source rewriting, and is,
itself, loaded as a package in an unmodified GNU R interpreter. To avoid code
changes, strictness information is provided by external signature files.
Providing signatures in external files avoids the need to modify the source code
of programs and also enables easy experimentation with different signature
configurations. We also support inline annotations, but they are not used in our
experiments.


\paragraph{Strictness Signatures.}
A signature file contains strictness signatures for functions of one or more
packages. The format is straightforward, a sequence of signatures \emph{sig} of
the form
%
\[
\mathit{sig}~~::=~~\mathsf{strict}~\mathsf{`pack}::\mathsf{fun`}~~\langle i, j, k, \dots\rangle
\]
%
Here, {\sf pack::fun} is the name of the package and function. The sequence of
integers specifies which argument positions are evaluated lazily. This format is
meant to be generated by our tools, inline annotations are more user-friendly. A
drawback of signature files is that inner functions can not be annotated as they
have no names. Only functions exported to a package namespace have a canonical
name. We considered various heuristics, but some packages dynamically set up
methods in package load hooks. This dynamism makes it hard to identify the
correct name. Luckily, these cases are a minority in R code.

\paragraph{Execution.}
Function are source-to-source rewritten as they are loaded. The rewriting is
simple; each function must \c{force} every argument that was not declared lazy.
Missing arguments are not forced. The implementation uses a feature of R that
allows registering callbacks when packages are loaded. \strictr registers a
callback that reads the signature file in the current directory or on the load
path. Then, as functions are defined, \strictr injects code in the function in
accordance with the signature. An earlier implementation mutated function
bodies. This resulted in failures as the same function object can occur with
different names and different signatures. For instance, in the \c{rlang}
package, \c{is_same_body <<- is_reference} aliases \c{is_reference}.
Mutating \c{is_reference} to make arguments strict inadvertently also makes
the function \c{is_same_body} strict. Further discussion will clarify why
this is undesirable. To avoid this, \strictr copies functions as it rewrites
them.

\paragraph{Intrinsic laziness.} When should an  argument be lazy?
We have found barely any use of functional programming idioms related to
call-by-need, such as infinite data structures. In fact, most code seems to be
written as if R was strict. There is one significant exception:
meta-programming. Consider the following:
\begin{lstlisting}
 f <- function(a,b) {
    print(deparse(substitute(a)))
    x <- eval(substitute(b))
    x+a
 }
\end{lstlisting}

\medskip

A call of \c{f(1+2,3+4)} creates two promises. The first is accessed by
\c{substitute}, turned into a string by \c{deparse} and printed. The code of the
second is accessed by \c{substitute} and evaluated by \c{eval}. Then expression
\c{x+a} forces the first promise; the second is never forced. Both arguments are
intrinsically lazy. Intrinsic laziness is transitive as arguments are passed
from one function to the next. If C code accesses a promise through the
\c{PREXPR} macro, the argument has to stay lazy for similar reasons. Lastly,
an argument that is not always evaluated may be marked as lazy. Though, this
is rarely necessary.

\paragraph{Accidental laziness.} In order to preserve the behavior of legacy
code, some parameters will be labeled as lazy even if the called function does
not require it. An argument that performs a side-effect is treated as lazy to
retain semantics. For instance in the call \c{f(g(),x<-1)}, function \c f is
free to evaluate its arguments in any order. Enforcing one particular order may
lead to observable differences in behavior, \eg if the call to \c{g()} reads
\c{x}. Writing such code is error prone, as small changes to \c f may break it.
R has a call-by-value semantics for vectors and lists. These are the most
frequently used data types, so many updates will be locally contained. Errors
and exceptions are another source of effects inside promises. Some reflective
functions can make evaluation of a promise sensitive to its position on the call
stack, and strict evaluation would be observable: \c{as.environment} and
\c{pos.to.env} use integers to access specific frames on the stack. It is
worth noting, again, that such code is brittle as any change in the the target
function can change the frame returned by the reflective calls.

Vararg arguments currently remain lazy. Assigning a single strictness annotation
to $\dots$ is tricky because a function can have different strictness behavior
for individual elements. This happens in object-oriented dispatch where the
vararg is forwarded from the dispatcher to the target method. One solution would
be to make vararg strict if it is strict in all of its constituents. However,
this may not occur frequently enough to justify the added complexity. The
current choice is pragmatic but imprecise; we are considering options for a more
accurate treatment.


\paragraph{Order of evaluation} A design choice we faced
was to select an evaluation order for strict arguments. One can retain the
evaluation order observed in the function if unique, but this obscure to
programmers. Another reasonable choice is to evaluate strict arguments
left-to-right at the call site and evaluate strict default values left-to-right
in the function prologue. This may be natural to users who wrote the call and
had control over the order of arguments and can reason about their potential
side effects. For convenience \strictr picks a third alternative. We evaluate
all arguments left-to-right in the order they appear in the function signature.
This means that end-users need to know in what order arguments are defined,
something that can be awkward as functions can have upward of 20 arguments. This
is convenient as \strictr rewrites function bodies and not call
sites.\footnote{There is a way to implement the second alternative as GNU R
keeps a \c{PROMARGS} list which stores promises in the same order as at the call
site.}



\section{LazR: A Scalable Infrastructure for Inferring Strictness}\label{sec:lazr}

\lazr is a pipeline for inferring strictness signatures for legacy R libraries
at scale. \lazr has two important components: a system for tracing the execution
of R scripts and an infrastructure for extracting executables and running
analyses that scale to thousands of packages.

\begin{figure}[!h]
  \begin{tabular}{lll}
    \begin{minipage}{6cm}
\begin{lstlisting}
 r1<-popular(FALSE,print('Hi'),3,4,5)
 r2<-popular(TRUE,1+2,stop(),0,9)
 r3<-popular(TRUE,1+2,3,r1<-4,r1+1)
\end{lstlisting}
    \end{minipage}
    &&
       \begin{minipage}{6cm}
\begin{lstlisting}
  popular <- function(a,b,c,d,e,f) {
     if (a) b
     print(substitute(c))
     if(!missing(f)) print(f)
     return e+d
 }
\end{lstlisting}
       \end{minipage}\\
    \it Client code&& \it Library
  \end{tabular}%
  \caption{Inferring strictness signatures}\label{iss} %
\end{figure}

The goal of this analysis is not to infer maximally strict signatures but rather
minimize the impact of semantic change on clients by considering both intrinsic
and accidental laziness. We elucidate this point with fig.~\ref{iss} which
shows a \c{popular} function that takes six arguments, \c{a} is always
evaluated, \c{b} is conditionally evaluated, \c{c} is forwarded to
\c{substitute} for meta-programming, \c{d} and \c{e} are forwarded to a
strict function, and \c{f} is evaluated if it is not missing. The client code
has three invocations. In all them, \c{f} is missing. This makes \c{f}
lazy because there is no information available about its evaluation. For \c{r1},
variable \c b should not be evaluated, evaluating it strictly will change the
output of the program; for \c{r2}, evaluating \c{c} will immediately
terminate execution, departing from the original program behavior; and for
\c{r3}, if \c{d} is evaluated before \c{e} a different result can be observed.
To summarize, the expected output of the analysis of legacy code is to increase
strictness while keeping the number of observable semantic differences low. For
new code, we expect programmers to mostly use strict parameters.

\paragraph{Tracing}
The heart of \lazr is a dynamic analysis tool built on the \rdyn package which
extends the GNU R virtual machine version 4.0.2~\cite{oopsla19b}. When \lazr
executes a script, it generates a \emph{trace} which is a sequence of low-level
events that mirrors the operations performed by the interpreter. As traces can
get large, rather than recording them, the infrastructure exposes callbacks that
are used to hook analysis-specific functionality to events. The trace exposes
raw R objects being operated on as well as control flow. To provide a layer of
abstraction, \lazr maintains \emph{model objects} to abstract from concrete R
data structures. These objects represent function instances, environments, and
stack frames. Model objects help handling some of the complexities of R. For
instance, they have unique identities, whereas R objects are identified by
memory address which can be reused. \lazr reclaims model objects and provides
efficient indexing. Model functions have names heuristically reconstructed and
keep track of lexical scopes. The model stack can deal with the use of
\c{longjump} for non-local returns. Lastly, \lazr maintains a notion of logical
time, used to record when some events of interest happened. For instance,
environments record the time of last read and last write. Similarly, code blocks
record evaluation start and end.

\paragraph{Inference}
\lazr monitors traces looking for signals that parameters are lazy. These
signals are relative to how the called function uses the parameter and what the
provided argument does, we summarize them here:
\begin{itemize}
\item[{\bf V}:] A vararg parameter; we consider this to be a strong
  signal of intrinsic laziness. The reason for this particular choice is that it
  is unclear how to treat individual elements of the varag.
\item[{\bf M}:] A parameter provided to \c{substitute} or \c{PREXPR} is
  \emph{meta-programmed}; this is a strong signal of intrinsic laziness.
\item[{\bf G}:] A parameter that did not receives an argument; this is a weak
  signal for laziness owing to a lack of information.
\item[{\bf U}:] A parameter that remains \emph{unevaluated}; this is a weak
  signal of intrinsic laziness as we do not know the contract of the function
  for that parameter.
\item [{\bf S}:] An argument with \emph{side-effects}; a weak signal of
  accidental laziness as some effects may be benign. We monitor three kinds of
  effects: variable reads, variable writes (definitions, updates, and removals)
  of variables, and errors. \lazr does not handle IO. The R ecosystem has a rich
  collection of libraries for handling data, resulting in a vast API for reading
  and writing files to disk. These functions call arbitrary C/C++ libraries for
  IO. Tracking these calls would require tracing \emph{syscalls} which is
  currently not supported by our dynamic analysis infrastructure.
\item[{\bf R}:] An argument that uses \emph{reflection} to observe the state of
  the call stack; this is a strong signal of accidental laziness as eager
  evaluation will evaluate the promise with a different stack.
\end{itemize}

For any trace, \lazr models each argument of each function. If a function is
invoked, the trace records all operations related to arguments and correlate
them with parameters. For each operation performed by the interpreter, the
analysis finds the responsible promises: all promises on the call stack. Since
each promise is bound to the argument of a function, one can connect that
promise to a corresponding parameter. When a side-effect or reflection occurs,
the parameters corresponding to all responsible promises are marked S or R.
Reads and writes are ignored in some cases. \lazr keeps track of the last
accessed and modified time of each binding. For a write from a promise, if the
binding being modified was not accessed after the promise was created and before
it stated executing, then the write is ignored because evaluating the promise
early will not introduce a conflict. Similarly, for reads, if the binding being
read was not modified after the promise was created and before it started
executing, then the read is ignored. For performance but at the cost of
precision, only the last 10K read and write times for each variable are
recorded.

The result of analyzing an R script is a summary for each function and each
parameter of the signals that were observed during tracing. Multiple scripts can
be straightforwardly merged as the union of signals for each parameter. Finally,
from this summary, strictness signatures are generated.

Consider Fig.~\ref{iss}, for \c{a} no signal is observed, for \c{b} signal U
come from \c{r1}, for \c{c} signal M comes from all invocations, for \c{d}
signal S comes from \c{r3} since its argument mutates \c{r1} after it is read by
\c{e}, we have no signal for \c{e}, and for \c{f} it gets \textbf{?} since \c
% SK shouldn't it be 'since is missing'? and remove e'
e is missing in all invocations. \lazr combines this information to synthesize
the signature, \texttt{strict popular<1,5>}, i.e., parameters \c{a} and \c{e}
are strict, and the rest are lazy.

Given a set of signals there are choices as how to merge them, especially if no
strong signal is observed. Conservatively one may choose to make a parameters
lazy at the first signal even if it is a weak one. Our design for \strictr
allows us to easily explore different merging strategies.

\section{\v R$_{\mathbf s}$: A Strict-by-default compiler}\label{sec:rsh1}

We considered several approaches to evaluate the performance of a change of
semantics. While one could expect that \strictr would be extended to optimize
strict functions, this was not straightforward in our proof of concept
implementation which does source-level rewriting. To achieve performance in the
GNU R implementation would have required changing the bytecode compiler and the
associated bytecode interpreter. While possible, the benefits one would measure
with such an approach would be bounded by the speed of interpreted code. It long
run, R implementations should generate native code. The alternative was to use
an experimental native compiler. There are two available in open source,
Oracle's Truffle implementation of R~\cite{Stadler16} and our own
\Rsh~\cite{dls19}. Both systems have their drawbacks. Truffle is not yet a
complete implementation of the language and it is unfamiliar to the authors.
\Rsh is less mature, in terms of optimizations, but runs all R programs. For
convenience, we picked \Rsh as a starting point.

One advantage of \Rsh is that it is based on the GNU R reference implementation
and can always defer to GNU R when it hits codes that is not supported. It
introduces an additional two-tiered compilation strategy. The first tier is
realized by a bytecode interpreter, the second tier by an optimizing native
compiler which relies on LLVM for code generation. The compiler employs, among
many other optimizations, speculative inlining of R closures and promises
\citep{dls19, oopsla20c}.
One benefit of choosing \Rsh is that it allows us to better evaluate the impact
of laziness. In \Rsh we can both measure the impact on an interpreter with few
optimizations applied to the bytecode, and an optimizing compiler that already
does its best to elide promises when the semantics of the language allows it.

We build \rshstrict as a minimal adaptation of \Rsh that can let us evaluate
performance benefits. We changed the first-tier compiler that generate the \Rsh
bytecode (which differs from the GNU R bytecode) to eagerly evaluate arguments,
unless the argument is marked as lazy. This eager bytecode also serves as the
source code for the optimizing tier.  The changes in the lower tier were minimal.
The benefits we show with \rshstrict are the lower bound on improvements as we
do not factor in strictness in the analysis passes and other optimizations of
the compiler.

\section{Inference Experiment}

The goal of the inference experiment is to evaluate what is the actual need for
laziness in legacy code and the robustness of our inference algorithm.
\lazr is scalable, it can handle all the packages in CRAN, but the amount of
data to process can reach multi-terabyte sizes. \lazr adopts a simple map-reduce
style. Analysis is split in phases shown in Fig.~\ref{ap}. The reduce maps a
function on the output of one trace to get a partial summary. The combine phase
concatenates partial summaries. Then, the summarize phase aggregates summaries
into a result table. Finally, the report phase creates graphs and tables for
inclusion in the paper. The \lazr pipeline is set up with a container image that
includes all the dependencies for installing analysis code and R packages. This
provides a reliable reproducible setup across machines. To run it, we mirror
repositories, install their packages, run the script to generate traces. These
traces are analyzed to output tabular data files and strictness signatures.
Whenever possible, we parallelize the steps. Our experiments were performed on
two Intel Xeon 6140, 2.30GHz machines with 72 cores and 256GB of RAM each.


\begin{figure}[h!]
  \centering
  \scalebox{0.85}{
    \begin{tikzpicture}
      \definecolor{maroon}{HTML}{D5A6BD}
      \definecolor{darkmaroon}{HTML}{741B47}
      \definecolor{yellow}{HTML}{FFF2CC}
      \definecolor{darkyellow}{HTML}{D6B656}
      \definecolor{blue}{HTML}{DAE8FC}
      \definecolor{darkblue}{HTML}{6C8EBF}
      \definecolor{green}{HTML}{D5E8D4}
      \definecolor{darkgreen}{HTML}{82B366}
      \definecolor{orange}{HTML}{FFE6CC}
      \definecolor{darkorange}{HTML}{D79B00}
      \definecolor{red}{HTML}{F8CECC}
      \definecolor{darkred}{HTML}{B85450}
      \definecolor{purple}{HTML}{E1D5E7}
      \definecolor{darkpurple}{HTML}{9673A6}
      \definecolor{gray}{HTML}{F5F5F5}

      \newcommand{\nodesep}[0]{0.030 \textwidth}
      \newcommand{\textsep}[0]{0.010 \textwidth}
      \newcommand{\backopacity}[0]{0.9}

      \newcommand{\nodename}[1]{\normalsize \begin{tabular}{c}#1\end{tabular}}
      \newcommand{\nodedesc}[1]{\small \begin{tabular}{c}#1\end{tabular}}

      \tikzstyle{block}     = [rectangle, rounded corners, minimum width=.08 \textwidth, minimum height=35pt]
      \tikzstyle{connector} = [line width=0.25mm, ->]

      \node [block, draw = darkmaroon, very thick, fill = maroon]                                (install)   {\nodename{Install\\CRAN}};
      \node [block, draw = darkyellow, very thick, fill = yellow, right = \nodesep of install  ] (extract)   {\nodename{Extract\\Programs}};
      \node [block, draw = darkblue,   very thick, fill = blue  , right = \nodesep of extract  ] (trace)     {\nodename{Trace}};
      \node [block, draw = darkgreen,  very thick, fill = green , right = \nodesep of trace    ] (reduce)    {\nodename{Reduce}};
      \node [block, draw = darkorange, very thick, fill = orange, right = \nodesep of reduce   ] (combine)   {\nodename{Combine}};
      \node [block, draw = darkred,    very thick, fill = red   , right = \nodesep of combine  ] (summarize) {\nodename{Summarize}};
      \node [block, draw = darkpurple, very thick, fill = purple, right = \nodesep of summarize] (report)    {\nodename{Report}};

      \draw [connector] (install)   edge (extract);
      \draw [connector] (extract)   edge (trace);
      \draw [connector] (trace)     edge (reduce);
      \draw [connector] (reduce)    edge (combine);
      \draw [connector] (combine)   edge (summarize);
      \draw [connector] (summarize) edge (report);

      \node [below = \textsep of install]   (installdesc)   {\nodedesc{8 Hours\\17,398 Packages}};
      \node [below = \textsep of extract]   (extractdesc)   {\nodedesc{5 Minutes\\500 Packages\\24,141 Scripts}};
      \node [below = \textsep of trace]     (tracedesc)     {\nodedesc{24 Hours\\240,520 Files\\966 GB}};
      \node [below = \textsep of reduce]    (reducedesc)    {\nodedesc{6 Hours\\XX Files\\38 TB}};
      \node [below = \textsep of combine]   (combinedesc)   {\nodedesc{1 Hour\\XX Files\\36.5 GB}};
      \node [below = \textsep of summarize] (summarizedesc) {\nodedesc{53 Minutes\\9 Files\\107 MB}};
      \node [below = \textsep of report]    (reportdesc)    {\nodedesc{XXs\\XX Files}};

      \begin{scope}[on background layer]
        \node[fit=(install) (extract), rectangle, rounded corners, fill=gray, fill opacity=\backopacity, label=above:\textbf{Corpus}]          (corpus) {};
        \node[fit=(trace),             rectangle, rounded corners, fill=gray, fill opacity=\backopacity, label=above:\textbf{Tracing}]         (exectrace) {};
        \node[fit=(reduce) (report),   rectangle, rounded corners, fill=gray, fill opacity=\backopacity, label=above:\textbf{Post-processing}] (postprocessing) {};
      \end{scope}
    \end{tikzpicture}
  }
  \caption{Analysis Pipeline}\label{ap}
\end{figure}

\subsection{Corpus}\label{sec:corpus}

A corpus of 500 packages with most client packages were selected from
CRAN~\cite{ligges2017} on the 26th of July 2021.

\begin{wraptable}{r}{7cm}
\small\centering
  \caption{Corpus}\label{table:corpus}
  \begin{tabular}{lrrr}\toprule
    &\bf Tests&\bf Examples&\bf Vignettes\\\midrule
    {Scripts}&\CorpusTestCount&\CorpusExampleCount&\CorpusVignetteCount\\\midrule
    {LOC}&\CorpusTestCode&\CorpusExampleCode&\CorpusVignetteCode\\\bottomrule
  \end{tabular}
\end{wraptable}%%


The packages have a total of \CorpusDependencyCount clients ranging from
\texttt{\CorpusMaximumDependencyPackage} with \CorpusMaximumDependencyCount clients
all the way to \texttt{\CorpusMinimumDependencyPackage} with only
\CorpusMinimumDependencyCount. The packages have \CorpusRCode lines of R code
and \CorpusNativeCode lines of native code. Table~\ref{table:corpus} summarizes
the runnable code. Each test is run as a separate script. Examples and vignettes
are snippets of code embedded in the documentation. \lazr extracts them into
self-standing scripts. Typically, vignettes are longer examples with input data,
while examples are smaller code fragments.


\begin{figure}[!h]  \centering
  \input{graphs/call_dist.tex}
  \caption{Call Distribution}\label{fig:callDist}
\end{figure}

The tracer encounters \TotalFunctionCount top-level functions;
\CorpusTwentyFivePackageCount packages have 25 functions or less, and
\CorpusFiveHundredPackageCount packages with more than 500 functions. The
largest package, \texttt{\CorpusMaximumFunctionPackage}, has
\CorpusMaximumFunctionCount functions. We observe \TotalCallCount calls to these
functions, their distribution per function is in Fig.~\ref{fig:callDist};
\CalledTenFunctionPerc of functions are called more than ten times, while
\CalledOneFunctionPerc are called only once. The traces record
\TotalArgumentCount arguments, of those, \MissingTotalCountArguments are
missing, \VarargParameterCount are varargs, and the remaining are promises.

\begin{figure}[!h]  \centering
  \input{graphs/param_dist.tex}
  \caption{Parameter Distribution}\label{fig:paramDist}
\end{figure}

These arguments correspond to \TotalParameterCount parameter positions, their
distribution per function is in Fig.~\ref{fig:paramDist}; \ZeroArityFunctionPerc
of functions have no parameters, \OneArityFunctionPerc have 1,
\TenArityFunctionPerc have over 10, and \FiftyArityFunctionCount functions have
over 50 parameters. Function \texttt{\MaxArityFunctionName} takes the cake with
\texttt{\MaxArityFunctionParamCount} parameters.

\subsection{Inferred strictness signatures}\label{sec:results}

There are three signals we consider strong, parameters marked by either one of
them are considered lazy. \lazr recorded 1.3K parameters being meta-programmed
(marked M), furthermore 3.2K were missing and 20K were varargs. All these remain
lazy. For other combinations of signals Table~\ref{table:strictdist} summarizes
their distribution. One function can be counted in multiple rows as its
different parameters may have different combinations. Rows are interpreted as
follows: the first row, for instance, indicates that no signals were observed
for 148K parameters coming from 49K functions and 489 packages.

\begin{table}[!h] \small
  \caption{Signature Summary} \label{table:strictdist} \centering
  \begin{tabular}{ccccccrrrrr}\toprule
    \bf V&\bf M&\bf G&\bf U&\bf S&\bf R&\multicolumn{2}{c}{\textbf{Parameters}} &\multicolumn{2}{c}{\textbf{Functions}}&\bf Packages\\\midrule
    \cmark{}&\xmark{}&\xmark{}&\xmark{}&\xmark{}&\xmark{}&20.0K&9.8\%&20.0K&38.8\%&430\\
    \xmark{}&\cmark{}&\xmark{}&\xmark{}&\xmark{}&\xmark{}&1.3K&0.6\%&825&1.6\%&118\\
    \xmark{}&\xmark{}&\cmark{}&\xmark{}&\xmark{}&\xmark{}&3.2K&1.6\%&1.7K&3.2\%&240\\
    \xmark{}&\xmark{}&\xmark{}&\xmark{}&\xmark{}&\xmark{}&148.4K&72.9\%&49.3K&95.7\%&489\\
    \xmark{}&\xmark{}&\xmark{}&\xmark{}&\xmark{}&\cmark{}&529&0.3\%&509&1\%&119\\
    \xmark{}&\xmark{}&\xmark{}&\xmark{}&\cmark{}&\xmark{}&1.3K&0.6\%&950&1.8\%&207\\
    \xmark{}&\xmark{}&\xmark{}&\xmark{}&\cmark{}&\cmark{}&76&0\%&74&0.1\%&22\\
    \xmark{}&\xmark{}&\xmark{}&\cmark{}&\xmark{}&\xmark{}&28.5K&14\%&12.4K&24.1\%&450\\
    \xmark{}&\xmark{}&\xmark{}&\cmark{}&\xmark{}&\cmark{}&33&0\%&32&0.1\%&24\\
    \xmark{}&\xmark{}&\xmark{}&\cmark{}&\cmark{}&\xmark{}&314&0.2\%&226&0.4\%&98\\
    \xmark{}&\xmark{}&\xmark{}&\cmark{}&\cmark{}&\cmark{}&9&0\%&9&0\%&5\\
    \bottomrule
  \end{tabular}
\end{table}

We observe that the majority of parameters (72\%) are always evaluated, and the
corresponding arguments do not perform side-effects or reflective operations.
These parameters can safely be evaluated eagerly. Unevaluated parameters account
for 14\% of observations, a significant source of potential laziness. Variable
lengths arguments and missing arguments account for 9\% and 1.6\% of the data
respectively. The remaining configurations are in the noise. It is noteworthy
that parameters marked R come from very few functions and packages.
We now discuss the different sources of laziness in more detail.

\paragraph{{\normalfont \textbf{[V]}} Varargs}
Some \VarargParameterCount parameters from \VarargFunctionCount functions are
marked \textbf{V} for \emph{vararg}.

\paragraph{{\normalfont \textbf{[M]}} Metaprogramming}
Table~\ref{table:metaprogramming} counts arguments, parameters and functions
using the metaprogramming facilities of R. Numbers are also provided for C code
that uses \c{PREXPR}. Arguments count all of the invocations of a function.

\begin{wraptable}{r}{5.5cm}\small\centering
  \caption{Metaprogramming}\label{table:metaprogramming}
  \begin{tabular}{lrrr}\toprule
    &\bf R&\bf Native&\bf Total\\\midrule
    {Arguments}&\MetaCountArgumentsR&\MetaCountArgumentsNative&\MetaCountArgumentsTotal\\
    {Parameters}&\MetaCountParametersR&\MetaCountParametersNative&\MetaCountParametersTotal\\
    {Functions}&\MetaCountFunctionsR&\MetaCountFunctionsNative&\MetaCountFunctionsTotal\\
   \bottomrule
  \end{tabular}
\end{wraptable}

For details about \c{substitute}, we refer the reader to \cite{oopsla19b}.
\c{PREXPR} was not addressed there: it is a C macro is used to extract a
promise's expression for ad-hoc evaluation strategies. Packages such as
\c{lazyeval} and \c{rlang} use it. \c{PREXPR} is also used by the builtins of
the GNU R interpreter, a canonical example is the \c{missing} function which
checks if an argument was provided. Unlike user packages, these uses of
\c{PREXPR} do not require the corresponding arguments to be lazily evaluated.
Hence, uses of \c{PREXPR} from the interpreter are not signals.


\paragraph{{\normalfont \textbf{[G]}} Missing Arguments}
Some \MissingAlwaysCountParameters parameters are always missing; they are
classified as \always. This is in contrast to the
\MissingSometimesCountParameters \sometimes parameters which are sometimes
passed an argument.

\begin{wraptable}{r}{5.76cm}\small\centering
  \caption{Missing}\label{table:missing}
  \begin{tabular}{@{}l@{}rrr@{}} \toprule
    &\bf Sometimes&\bf Always&\bf Total\\\midrule
    {Argments}&\MissingSometimesCountArguments&\MissingAlwaysCountArguments&\MissingTotalCountArguments\\
    {Parameters}&\MissingSometimesCountParameters&\MissingAlwaysCountParameters&\MissingTotalCountParameters\\
    {Functions}&\MissingSometimesCountFunctions&\MissingAlwaysCountFunctions&\MissingTotalCountFunctions\\\bottomrule
  \end{tabular}
\end{wraptable}

Table~\ref{table:missing} gives numbers of missing arguments and parameters.
\always parameters are a strong signal, whereas \sometimes missing are only lazy
if also marked U. In the following definition the \c{names} argument was missing
in all calls to this function from \c{rlang}, it is thus an \always parameter.
That fact is not surprising when inspecting the code of the function: the
argument is not used! It is presumably only there for backwards compatibility.

\begin{lstlisting}
 new_environments <- function(envs, names) {
   stopifnot(is_list(envs))
   structure(envs,names=map_chr(unname(envs),env_name),class="rlang_envs")
 }
\end{lstlisting}

For a \sometimes parameter, consider the \c{linewidth} argument which is missing
in some calls to this function which assigns a default value of \c{0L} to
\c{linewidth}.

\begin{lstlisting}
 base64encode <- function(what, linewidth, newline) {
   linewidth <- if (missing(linewidth) || !is.numeric(linewidth)) 0L
                 else as.integer(linewidth[1L])
\end{lstlisting}


\begin{wraptable}{r}{6cm}\small\centering
  \caption{Unevaluated}\label{table:unevaluated}
  \begin{tabular}{lrrr}\toprule
    &\bf Sometimes&\bf Never&\bf Total\\
    \midrule
    {Parameters}&\UnevaluatedSometimesCountParameters&\UnevaluatedNeverCountParameters&\UnevaluatedTotalCountParameters\\
    {Functions}&\UnevaluatedSometimesCountFunctions&\UnevaluatedNeverCountFunctions&\UnevaluatedTotalCountFunctions\\
    \bottomrule
  \end{tabular}
\end{wraptable}

\paragraph{{\normalfont \textbf{[U]}} Unevaluated Arguments}
Some parameters are \sometimes evaluated and others are \never evaluated. The
latter may correspond to code paths not exercised or to dummy parameters.
Table~\ref{table:unevaluated} has numbers for both categories. A common pattern
is to evaluate one argument only if another has a given value.

\begin{lstlisting}
 %||% <- function(x,y) if(is.null(x)) y else x
\end{lstlisting}

Another pattern is to delay evaluation: \c{expr} is delayed until \c{pkg} is
loaded.

\begin{lstlisting}
 glue::on_package_load <- function(pkg, expr) {
   if (isNamespaceLoaded(pkg)) { expr } else {
     thunk <- function(...) expr
     setHook(packageEvent(pkg, "onLoad"), thunk)
 } }
\end{lstlisting}

S3 generic methods are functions dynamically dispatched: here, \c x is always
evaluated in order to dispatch, the others depend on where the call dispatches
to.

\begin{lstlisting}
 abind::acorn <- function(x,n=6,m=5,r=1,...) UseMethod('acorn')
\end{lstlisting}

Some functions implement a common interface, the \c{proxy} package defines over
a dozen methods with interface \c{function(a,b,c,d,n)} to compute different
proximity metrics with a subset of the arguments. Arguments can also be \never
by design; \c{tail} is not defined for \c{tbl_lazy} objects.

\begin{lstlisting}
 dbplyr::tail.tbl_lazy <- function(x, n = 6L, ...)
   stop("tail() is not supported by sql sources", call.=FALSE)
\end{lstlisting}


\paragraph{{\normalfont \textbf{[S]}} Side-Effects}
Few promises have side-effects and many of those are benign for our purposes as
they happen to local variables of the promise. Table~\ref{table:effects}
presents the number of parameters that are made lazy due to observable
side-effects. Only \EffectCountArgumentsTotal arguments out of \todo{add total
  argument macro} are made lazy owing to effects. This corresponds to
\EffectCountParametersTotal lazy parameters from \EffectCountFunctionsTotal
functions.

\begin{table}[h]
  \small\centering
  \caption{Side-Effects}\label{table:effects}
  \begin{tabular}{rrrr}\toprule
    \bf Arguments&\bf Parameters&\bf Functions&\bf Packages\\
    \midrule
    \EffectCountArgumentsTotal&\EffectCountParametersTotal&\EffectCountFunctionsTotal&\EffectCountPackagesTotal\\
    \bottomrule
  \end{tabular}
\end{table}

A typical example of this category is the \code{along} parameter of \code{abind}
function from the \code{abind} package. Its default value is the parameter
\code{N} which is computed internally in the body of the function before
\code{along} is used. Clearly, the evaluation of \code{along} has to be delayed.

\begin{lstlisting}
abind <- function(..., along=N, ...) {
    N <- max(1, sapply(arg.list, function(x) length(dim(x))))
    if (!is.null(rev.along))
        along <- N + 1 - rev.along
}
\end{lstlisting}

Another example is the \code{expr} parameter of \code{withPrivateSeed} function
from the \code{shiny} package. This function evaluates \code{expr} after setting
the global random number generator seed to its own private value. The seed is
set back to its initial value on function exit. The \code{expr} parameter should
not be evaluated until the seed has been changed, hence it made lazy by \lazr.

\begin{lstlisting}
withPrivateSeed <- function(expr) {
  origSeed <- .GlobalEnv$.Random.seed
  GlobalEnv$.Random.seed <- .globals$ownSeed
  on.exit({.GlobalEnv$.Random.seed <- origSeed})
  expr
}
\end{lstlisting}

\paragraph{{\normalfont \textbf{[R]}} Reflection}
Reflective code is brittle. The following example shows that code that looks up
its call stack is sensitive to small implementation changes, such as the
addition of a call to an identity function. The evaluation of \c x and \c y will
yield different results as the latter is executing within the \c{id} function.
%
\begin{lstlisting}
 f <- function(x, y) { x; y }
 f(as.environment(-1), as.environment(-1))
 id <- function(a) a
 f <- function(x, y) { x; id(y) }
 f(as.environment(-1), as.environment(-1))
\end{lstlisting}
%

This can transitively affect the strictness of other parameters. If \c{f} is
called from \c{g}, we must make \c{g} lazy. R provides other functions for
reflective stack access, \c{parent.frame} and \c{sys.frame}; these are less
brittle as they access frames relative to the promise's creation environment.

\begin{lstlisting}
 g <- function(u, v) { f(u, v) }
 g(as.environment(-1), as.environment(-1))
\end{lstlisting}


\begin{wraptable}{r}{5.5cm}
  \small
  \centering
  \caption{Reflection}\label{table:reflection}
  \begin{tabular}{lrrr}
    \toprule
    &\bf Direct&\bf Transitive&\bf Total\\
    \midrule
    {Arguments}&\RefCountArgumentsDirect&\RefCountArgumentsTransitive&\RefCountArgumentsTotal\\
    {Parameters}&\RefCountParametersDirect&\RefCountParametersTransitive&\RefCountParametersTotal\\
    {Functions}&\RefCountFunctionsDirect&\RefCountFunctionsTransitive&\RefCountFunctionsTotal\\    \bottomrule
  \end{tabular}
\end{wraptable}

Table~\ref{table:reflection} presents the number of arguments that probe the
call stack either directly or transitively. This does not count cases where the
argument is also metaprogrammed. Parameters from two functions,
\c{.getFunctionByName}, and \c{backports:::get0} call these functions directly.
The first searches for a function by name in different scopes. Its argument has
a default value of \c{as.environment(-1)}.

\begin{lstlisting}
 R.oo:::.getFunctionByName <-
   function(...,
            callEnvir = as.environment(-1L)) {
    envirT <- callEnvir
    #...
 }
\end{lstlisting}
%

\subsection{Robustness of inferred signatures} \label{Evaluation:Robustness}


\begin{wraptable}{r}{6cm}  \small  \centering
  \caption{Client Corpus}\label{table:clientcorpus}
  \begin{tabular}{lrrr}    \toprule
    &\bf Tests&\bf Examples&\bf Vignettes\\
    \midrule
    {Scripts}&\ClientTestCount&\ClientExampleCount&\ClientVignetteCount\\\midrule
    {LOC}&\ClientTestCode&\ClientExampleCode&\ClientVignetteCode\\\bottomrule
  \end{tabular}
\end{wraptable}%%

In this section, we evaluate the robustness of strictness signatures generated
by \lazr. This is done by running scripts extracted from 2,000 client packages
of our corpus. These packages have \ClientRCode lines of R code and
\ClientNativeCode lines of native code. Table ~\ref{table:clientcorpus} gives
the number of scripts and lines of code exercised. Using \lazr, we extracted 52K
scripts from the clients. From these, we filtered scripts whose output was
non-deterministic, leaving us with 42K scripts. The goal of the next step is to
validate if, after applying strictness signatures, they produce identical
outputs. Comparing the output of scripts is standard practice in the R community
for detecting regressions. There may be a difference in execution that does not
manifest in the output; this may hide some errors, so the results reported here
should be considered a lower bound.

\begin{figure}[!b]
  \centering
  \scalebox{0.7}{
    \begin{tikzpicture}

      \definecolor{gray}{HTML}{F5F5F5}
      \definecolor{green}{HTML}{D5E8D4}
      \definecolor{darkgreen}{HTML}{82B366}
      \definecolor{yellow}{HTML}{FFF2CC}
      \definecolor{darkyellow}{HTML}{D6B656}
      \definecolor{blue}{HTML}{DAE8FC}
      \definecolor{darkblue}{HTML}{6C8EBF}
      \definecolor{purple}{HTML}{E1D5E7}
      \definecolor{darkpurple}{HTML}{9673A6}
      \definecolor{red}{HTML}{F8CECC}
      \definecolor{darkred}{HTML}{B85450}

      \tikzstyle{block}      = [rectangle, rounded corners, minimum width=.12 \textwidth, minimum height=35pt]
      \tikzstyle{dummyblock} = [rectangle, rounded corners, minimum width=.10 \textwidth, minimum height=22pt]

      \tikzstyle{connector} = [line width=0.25mm, ->]

      \newcommand{\nodesep}[0]{0.060 \textwidth}
      \newcommand{\dummynodesep}[0]{8mm}
      \newcommand{\textsep}[0]{10mm}
      \newcommand{\backopacity}[0]{0.9}

      \newcommand{\nodename}[1]{\large \begin{tabular}{c}#1\end{tabular}}
      \newcommand{\nodedesc}[1]{\small \begin{tabular}{c}#1\end{tabular}}

      \node [block,      draw = darkgreen,  very thick, fill = green]                                                           (corpus)            {\nodename{Corpus}};
      \node [block,      draw = gray,       very thick, fill = gray,   right = \nodesep of corpus]                              (dummyrun)          {};
      \node [block,      draw = darkyellow, very thick, fill = yellow, above = \dummynodesep of dummyrun.north, anchor = north] (runone)            {\nodename{First\\Run}};
      \node [block,      draw = darkyellow, very thick, fill = yellow, below = \dummynodesep of dummyrun.south, anchor = south] (runtwo)            {\nodename{Second\\Run}};
      \node [block,      draw = darkblue,   very thick, fill = blue,   right = \nodesep of dummyrun]                            (outone)            {\nodename{Compare\\Output}};
      \node [block,      draw = darkpurple, very thick, fill = purple, right = \nodesep of outone]                              (strictrun)         {\nodename{Run with\\StrictR}};
      \node [dummyblock, draw = gray,       very thick, fill = gray,   above = 0mm of strictrun.north]                          (dummystrictrun)    {};
      \node [dummyblock, draw = gray,       very thick, fill = gray,   below = 0mm of strictrun.south]                          (dummystrictruntwo) {};
      \node [block,      draw = darkred,    very thick, fill = red,    right = \nodesep of strictrun]                           (outtwo)            {\nodename{Compare\\Output}};

      \draw [connector] (corpus)       -- (runone.west);
      \draw [connector] (corpus)       -- (runtwo.west);
      \draw [connector] (runone.east)  -- (outone);
      \draw [connector] (runtwo.east)  -- (outone);
      \draw [connector] (outone)       -- (strictrun);
      \draw [connector] (strictrun)    -- (outtwo);
      \draw [connector] (runtwo.south) -- ++(0, -0.2) -| ($(runtwo) !1.0! (outtwo.south)$);

      \node [below = \textsep of corpus]    (corpusdesc)     {\nodedesc{XXs\\XX Packages\\XX Files}};
      \node [below = \textsep of dummyrun]  (rundesc)        {\nodedesc{XXs}};
      \node [below = \textsep of outone]    (outonedesc)     {\nodedesc{XXs\\XX Files}};
      \node [below = \textsep of strictrun] (strictrundesc)  {\nodedesc{XXs\\XX Signatures}};
      \node [below = \textsep of outtwo]    (outtwodesc)     {\nodedesc{XXs\\XX Files}};

      \begin{scope}[on background layer]
        \node[fit=(corpus) (runone) (runtwo) (outone),                       rectangle, rounded corners, fill=gray, fill opacity=\backopacity, label=above:\textbf{Deterministic Corpus}] (detcorpus) {};
        \node[fit=(strictrun) (dummystrictrun) (dummystrictruntwo) (outtwo), rectangle, rounded corners, fill=gray, fill opacity=\backopacity, label=above:\textbf{Failures}] (failures) {};
      \end{scope}

    \end{tikzpicture}
  }
  \caption{Validation Pipeline}\label{fig:validationPipeline}
\end{figure}

Fig.~\ref{fig:validationPipeline} shows the full pipeline, it starts with extracting
runnable code, then performs two runs with default semantics to check if the
script is deterministic. If it is, the result of a run with strict semantics is
compared and differences a recorded.


We explored various degrees of strictness by choosing which of the three weak
signals to treat as requiring lazy evaluation. Table~\ref{table:strictfail}
reports on the eight configurations we evaluated. For each row in the table, we
ran all 42K scripts and counted the number of differences from expected outputs.
Each row corresponds to a different set of strictness signatures for the corpus.
For each configuration, we report the number and percentage of failing programs.
The \emph{+} sign indicates the corresponding parameter is lazy and \emph{-}
means strict. For example, in the $+U+S+R$ configuration, any parameter marked
as either U, S or R, is lazy, whereas the configuration $+U+S-R$ means that any
parameter marked U or S must be lazy, and the configuration $-U+S+R$ means that
parameters marked S and \SK{or, right?} R must be lazy.


\begin{wraptable}{r}{5cm}
  \small
  \caption{Strictness Failure} \label{table:strictfail}
  \centering
  \begin{tabular}{lc|ll}
    \toprule
    \#&\textbf{Configuration}&\multicolumn{2}{c}{\textbf{Failures}}\\
    \midrule
    0&$+U+S+R$&239&0.56\%\\
    1&$+U+S-R$&234&0.55\%\\
    2&$+U-S+R$&1922&4.51\%\\
    3&$+U-S-R$&6625&15.54\%\\
    4&$-U+S+R$&610&1.43\%\\
    5&$-U+S-R$&616&1.44\%\\
    6&$-U-S+R$&2319&5.44\%\\
    7&$-U-S-R$&7158&16.79\%\\
    \bottomrule
  \end{tabular}
\end{wraptable}

\cconfig 0 is the laziest and only 239 scripts out of 42K have erroneous
outputs. These errors come from some of the unmarked parameters. Consider, for
instance, a library function \c f that was always called without side-effects
during inference and for which there is a side-effecting client. \lazr would
mark that function as strict, but the client may be able to observe the semantic
difference. Luckily, this is quite rare.

Other configurations are stricter, and thus should experience more errors.
\cconfig 1 is surprising, as making reflective arguments strict hides 5 errors;
this is an outlier. At the end of the spectrum, \config 7 makes all parameters
marked either U, S, or R strict and experiences 16\% of failures which is rather
high. This suggests a substantial amount of accidental laziness is observed.

One take away is that unevaluated parameters have only a small impact on errors,
while S and R are the cause of most errors. We conclude that \config 0 is a safe
starting point for migration. Manual tightening of the signatures can start with
the reflective argument and look at side-effecting ones on a case-by-case basis.

\section{Performance Experiment}\label{sec:rsh}

Our hypothesis is that eager semantics lead to faster programs. This might
surprise readers who expect call-by-need avoids unnecessary computation.
Delaying computations is complex and hinders performance in two ways. First, it
leads to more allocation. Second, it obstructs compiler analyses and
optimizations. We expect the hypothesis to hold for a just-in-time compiler that
uses advanced optimizations like \Rsh. In particular, we expect: (1) eager
semantics to improve performance of most benchmarks, for both tiers of \Rsh; (2)
a portion of the speedup to come from reduced garbage collection; (3) and an
additional speedup due to improved compiler optimizations. We present our
evidence in support of (1) and (3), and partial evidence for (2).

\paragraph{Methodology}
We conducted a limit-study experiment to assess the highest achievable
performance given the current state of the compiler. We manually picked the
strictest, semantically-correct, signatures for our programs. Only a handful of
functions, such as \lstinline{tryCatch}, had to be kept lazy.
Table~\ref{table:bms} gives our benchmarks. We picked a subset of the \Rsh
benchmark suite which includes one variant of each benchmark. We acquired one
real-world program, \c{flx}, and ported three programs from the \emph{Are we
fast} suite to R. All of these are available with our artifact.

\begin{wrapfigure}{r}{6cm}
  \small
  \caption{Benchmarks}\label{table:bms}
  \begin{tabular}{lll}
    \toprule
    \bf Id&\bf Benchmark&\bf Suite\\
    \midrule
    bnc&Bounce&Are we fast\\
    mnd&Mandelbrot&Are we fast\\
    sto&Storage&Are we fast\\
    flx&Flexclust&Real thing\\
    bin&Binarytrees&Shootout\\
    fst&Fasta&Shootout\\
    far&Fastaredux&Shootout\\
    fnk&Fannkuchredux&Shootout\\
    knu&Knucleotide&Shootout\\
    nbo&Nbody&Shootout\\
    pdg&Pidigits&Shootout\\
    rgx&Regexdna&Shootout\\
    rev&Reversecomplement&Shootout\\
    spn&Spectralnorm&Shootout\\
    \bottomrule
  \end{tabular}
\end{wrapfigure}


Experiments are run on a dedicated benchmarking machine, with all background
tasks disabled. The system features an Intel i7-6700K CPU, stepping 3, microcode
0xe2 with 4 cores and 8 threads. The system has 32 GB of RAM and is running
Ubuntu 18.04 on a 4.15.0-136 Linux kernel. For ease of use, experiments are
built as containers, based on Ubuntu 20.04, and executed on the Docker runtime
20.10.5, build 55c4c88. We verified the overhead introduced by the
containerization to be uniform. All measurements are recorded repeatedly and we
keep a historical record to spot unstable behavior. This led us to exclude the
\lstinline{convolution} benchmark as it appears to have a bi-modal performance
profile, likely caused by the LLVM backend. Performance measurements are
gathered by running $t_e$ invocations of \Rsh on each benchmark. Within each
invocation we measure the execution time of $t_i$ in-process invocations. For
each invocation, the first 5 in-process iterations are discarded to exclude
warmup behavior. Aggregate numbers are reported as the speedup over the
arithmetic mean of the execution times. Multiple speedup numbers are averaged
using a geometric mean. As a baseline we use \Rsh which already has a
\speedupRsh mean speedup over GNU R on our subsetted benchmark suite, with
parameters $t_e = 1, t_i = 15$. Speedup ranges between \speedupRshMin and
\speedupRshMax.

\paragraph{Speedup}

\begin{figure}[h]
  \centering \input{graphs/rshStrictPerf.tex}
  \caption{Speedup} \label{fig:speedup}
\end{figure}

First, we compare \Rsh against \rshstrict. This experiment estimates the
end-to-end improvement on performance that a change to eager semantics in the R
language would have on \Rsh. The execution times were measured with $t_e = 4,
t_i = 25$. \autoref{fig:speedup} shows a boxplot for the speedups of \rshstrict
along the X-axis, normalized with respect to \Rsh (lazy). Outliers are
represented by black dots. Overall, we observe a mean speedup of
\speedupRshStrict, ranging from \speedupRshStrictMin to \speedupRshStrictMax.
For \speedupRshStrictSignificant out of \benchmarkSuiteSize benchmarks we
measure a significant increase in performance.
%
\begin{figure}[h]
  \centering
  \input{graphs/rshStrictPerfBc.tex}
  \caption{Speedup without optimizations}
  \label{fig:speedup-bc}
\end{figure}
%

Then, we repeated the performance experiment, but with the second tier optimizer
completely disabled. In other words, we compare non optimized variants of
\rshstrict vs. \Rsh. Since this variant executes overall \rshBCSlowdown slower,
we chose to only run with $t_e = 1, t_i = 15$. The results are presented in
\autoref{fig:speedup-bc}. We found that the bytecode interpreter also gains a
speedup of \speedupBCRshStrict, ranging from \speedupBCRshStrictMin to
\speedupBCRshStrictMax.
%
Thus, we conclude that in our benchmark suite both a naive interpreter and a
speculatively optimizing native compiler achieve better performance on a strict
dialect of R. Even though the speedup is very similar in numbers, the reasons
seem to be different at times. We will get back to that point in the discussion
at the end of this section.


\begin{figure}[h]
  \centering
  \input{graphs/rshPromNorm.tex}
  \caption{Promises allocated, normalized to GNU R. The right column shows GNU R's actual promises. If the bar is too small to display, we show the actual number of promises in the respective experiment.}
  \label{fig:gc-pressure}
\end{figure}

\paragraph{Garbage Collection}
We measure the number of promises allocated per iteration for GNU R, \Rsh, and
\rshstrict. The results are shown in \autoref{fig:gc-pressure}. We report on the
geometric mean of the reductions in each benchmark. The first jump from GNU R's
bytecode interpreter to the optimizing just-in-time compiler \Rsh, leads to a
\promiseAlocationReductionGnurRsh reduction in allocations. The number is
reached by taking the geometric mean of light-gray bars, yielding a
\promiseAllocationGnurRsh. Therefore, the reduction is
\promiseAlocationReductionGnurRsh ({$100\%$\xspace} -
\promiseAllocationGnurRsh). Note that for some benchmarks the light-gray bar is
too small to be seen and replaced by the actual number. The second step from
lazy to eager semantics leads to \promiseAlocationReductionRshStrictToZero
benchmarks not allocating any promises at all. On the remainder, we see an
additional \promiseAlocationReductionRshStrict reduction (\rshstrict normalized
to \Rsh).

Overall, \promiseAlocationReductionRshStrictToZero benchmarks reduce to zero
allocations, the rest reduce on average by
\promiseAlocationReductionGnurRshStrict. To reach this number, once again we
compute the geometric mean of dark bars, yielding
\promiseAllocatioGnurRshStrict. Therefore, the reduction is
~\promiseAlocationReductionGnurRshStrict ({$100\%$\xspace} -
\promiseAllocatioGnurRshStrict).
The lowest reduction observed is \promiseAlocationReductionGnurRshStrictMin.
Surprisingly the number of remaining promises is still relatively high in some
cases. As far as we were able to observe, they originate largely from special
forms, \ie R builtins with a custom evaluation strategy, that are not yet
natively supported in the \Rsh bytecode.

It turns out that even an optimizing compiler has to allocate many promises for
R code, as oftentimes, they cannot be eliminated entirely. \rshstrict allows for
a larger reduction in the number of promises allocated. Thus, we expected a
significant portion of the overall speedup to originate from the reduced
allocation rate. We measured the differences in garbage collection time and it
ranged from \speedupGCRshStrictMin to \speedupGCRshStrictMax, but found the
contribution to the overall speedup to be smaller than expected. The GNU R
garbage collector, which is reused in \Rsh, has a fairly slow allocation path,
which includes mutating a doubly-linked list. Therefore, some portion of the
speedup could be due to the saved time in the allocation of promises, which is
not counted in the GC time. We therefore conducted an additional experiment,
where we evaluated arguments to calls eagerly, but additionally allocated a
promise only to be subsequently discarded. This configuration led to an overall
speedup of \speedupBCRshStrictAlloc instead of \speedupBCRshStrict, suggesting
that about \speedupDueToReducedGC of the performance improvement in the bytecode
interpreter is due to the reduced allocation. Unfortunately, a similar
experiment cannot be as easily conducted for the optimizing tier of \Rsh, since
its compiler would just optimize away all unnecessary allocations. We conjecture
that the contribution should be even smaller in that case, because it allocates
much fewer promises to start with.

\paragraph{Discussion}

In both tiers, we observed a proportional reduction of time spent tracing the
heap and allocating promises. Surprisingly, that was not the main reason
for the speedups. We investigated the remaining difference using the
\lstinline{perf} profiler and found that the overheads of lazy evaluation are to
be found in setting up the execution context for promise evaluation. This
includes marking it as 'executing' to detect recursive evaluation dependencies,
and either calling the interpreter's main eval-loop on the code of the promise or
calling the compiled function. In the case of the native backend, having the
promises inlined at the call-site instead of in a separate native function
invoked by the callee, resulted in fewer instruction cache misses. We also found
some instances where both tiers sped up similarly, however, the underlying
reasons were very different. Take for instance the \lstinline{bin} benchmark,
which showed in both interpreter and compiler a speedup of about $1.5\times$ in
the strict mode. In native, the execution time decreased from 79ms to 53ms. In
the interpreter, time went from 143ms to 97ms per iteration. In the former case,
the speedup comes from the effects described above; for the latter, part of the
speedup is due to better optimizations. Previously the local environment of
the innermost function was live. Thanks to eager evaluation of the arguments,
the argument promises do not leak the environment and therefore \Rsh is able to
elide it.

\section{Conclusion}\label{sec:conclusion}

In R, function arguments are not evaluated at the call-site, instead, the
evaluation is suspended until the callee needs it. The definition of
\emph{need} is quite liberal here as, for example, local re-binding, returning,
and many builtin functions are strict. As was reported in previous work, this
leads to many programs being on the eager side of the spectrum for a lazy
language. Why is R lazy at all? It turns out that allowing users to reflectively
alter argument expressions, before evaluating them, is a very expressive and
powerful meta-programming technique, enjoyed by many package authors in the R
ecosystem to build, \eg embedded domain specific languages. It is part of
what makes R appealing to its users, even if they do not realize that the
language they use has a lazy core. However, the joy is limited when it comes to
writing robust R code --- as both the caller and the callee co-determine what a function
actually does --- and also when implementing the language itself. When we turned
R into a mostly strict mode, the \Rsh just-in-time compiler ran
\speedupRshStrict faster through our benchmarks without any further changes.
Taking everything into account, we believe that R should be strict by default,
giving package authors the option to opt-in to laziness. We provide a strategy
for R as an ecosystem to get there by automatically inferring robust strictness
signatures for package code. These signatures try to capture the desired and
accidental laziness of arguments passed to R packages, thereby allowing most of
the client code to run unchanged --- in our experiments, only \robustnesResult of
all depending packages' tests failed. Such automatically generated strictness
signatures can then subsequently be refined by the package authors and users.
The change to the language would be beneficial in several ways. Implementations
would become faster, compilers and program analysis easier to perform, users
would be presented with a more commonly expected call semantic, and it would open
up the path for further evolution. Currently, many standard techniques such as
gradually typed function signatures and efficient just-in-time optimizations are
difficult to apply to R because of laziness.

\bibliography{bib/jv,bib/aviral,bib/ml,bib/bib}

\end{document}
