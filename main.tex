\documentclass[review,nonacm,screen,acmsmall,anonymous=true]{acmart}
\settopmatter{printfolios=true,printccs=true,printacmref=true}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}   %% For author/year citations
\usepackage{listings,multirow,wrapfig,xspace}
\usepackage{xcolor,tikz,graphicx, pifont}
%\usetikzlibrary{positioning}

\newcommand{\authorcomment}[3]{\xspace\textcolor{#1}{{\bf #2} #3}\xspace}
% For author notes:
\newcommand{\AG}[1]{\authorcomment{orange}{AG}{#1}}
\newcommand{\JV}[1]{\authorcomment{red}{JV}{#1}}
\newcommand{\JJ}[1]{\authorcomment{green}{JJ}{#1}}
\newcommand{\SK}[1]{\authorcomment{yellow}{SK}{#1}}
\newcommand{\OF}[1]{\authorcomment{magenta}{OF}{#1}}

% For meta comments:
\newcommand{\isit}[1]{\authorcomment{cyan}{Check}{#1}}
\newcommand{\todo}[1]{\authorcomment{red}{TODO}{#1}}
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}
\newcommand{\cmark}{\textcolor{green}{\ding{51}}}

\newcommand{\always}{\emph{Always}\xspace}
\newcommand{\sometimes}{\emph{Sometimes}\xspace}
\newcommand{\sometimesStar}{\emph{Sometimes*}\xspace}
\newcommand{\never}{\emph{Never}\xspace}
\newcommand{\neverStar}{\emph{Never*}\xspace}
\newcommand{\rdyn}{{\sf R-dyntrace}\xspace}
\newcommand{\instr}{{\sf InstrumentR}\xspace}

\lstset{language=R}

\definecolor{LightGray}{RGB}{247, 247, 247}
\definecolor{Gray}{rgb}{.3,.3,.3}
\definecolor{DarkGray}{rgb}{.5,.5,.5}

\lstset{ %
  columns=flexible,
  captionpos=b,
  frame=single,
  framerule=0pt,
  framexleftmargin=1mm,
  framexrightmargin=1mm,
  tabsize=2,
  belowskip=0pt,
  basicstyle=\small\ttfamily,
  backgroundcolor=\color{LightGray},
  emphstyle=\sffamily,
  keywordstyle=\bfseries,
  commentstyle=\color{Gray}\em,
  stringstyle=\color{Gray}
}
\lstdefinestyle{R}{ %
  language=R,
  deletekeywords={new, env, equal, c, runif, trace, args, exp, t, all, get,body,
    names, is, environment, class, substitute, expression, list, null, Internal,
    sample, diag, length, rep, nrow, stop, offset, pmax, Machine,check,names,merge,all,
    double, parent, frame, par, methods, end, dir, apply, deparse, missing,any,
    plot, as, integer, character, inherits, numeric, paste, eval, quote, call,
    formula, df, log, sum, c, local, legend, file, scale, round, title, order,
    drop, which, grid, print, ncol, dim, max, format, sort, rug, matrix, start,
    unique, mean, df, attr, do, power},
  otherkeywords={},
  breaklines=true
}

\newcommand{\code}[1]{\lstinline[style=R]|#1|\xspace}
\renewcommand{\c}[1]{\lstinline[style=R]|#1|\xspace}
\newcommand{\strictr}{{\sf StrictR}\xspace}
\newcommand{\lazr}{{\sf LazR}\xspace}
\renewcommand{\Rsh}{{\sf\u R}\xspace}
\newcommand{\Rshstrict}{{\sf\u R-strict}\xspace}

\newcommand{\eg}{\emph{e.g.},\xspace}
\newcommand{\ie}{\emph{i.e.},\xspace}

\include{results}

%%% \setcopyright{rightsretained}
%%% \acmPrice{}
%%% \acmDOI{10.1145/3360579}
%%% \acmYear{2019}
%%% \copyrightyear{2019}
%%% \acmJournal{PACMPL}
%%% \acmVolume{3}
%%% \acmNumber{OOPSLA}
%%% \acmArticle{153}
%%% \acmMonth{10}
\begin{document}
\title{Promises Are Made To Be Broken}
\subtitle{Migrating the R ecosystem to strict evaluation semantics}

\author{Aviral Goel}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Ječmen}\affiliation{\institution{Czech Technical University}\country{Czechia}}
\author{Sebastián Krynski}\affiliation{\institution{Czech Technical University}\country{Czechia}}
\author{Olivier Flückiger}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Vitek}\affiliation{\institution{Czech Technical University and Northeastern University}\country{USA}}
\authorsaddresses{}
\renewcommand{\shortauthors}{Goel, Vitek}

\begin{abstract}
  Function calls in the R language do not evaluate their arguments; these are
  passed as suspended computations to the callee which evaluates them only if
  they are needed. After 25 years of experience with the language, there are
  very few cases where programmers leverage delayed evaluation intentionally.
  Yet, being lazy comes at a price in performance and complexity. This paper
  explores how one could evolve the semantics of the language towards strictness
  by default and laziness on demand. To provide a migration path, it is
  necessary to change the semantics of the language implementations and provide
  tooling for developers to migrate the libraries and user code in a way that
  does not introduce errors. This paper reports on a dynamic analysis that
  infers strictness signatures for functions and capture both intentional and
  accidental laziness. To assess the robustness of the inferred signatures, we
  implemented a source-to-source refactoring that forces the evaluation of
  arguments that have been annotated as strict. Finally, we report on the
  performance benefits of migration by extending a just-in-time compiler with
  support for strictness annotations.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002944.10011123.10010912</concept_id>
<concept_desc>General and reference~Empirical studies</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011050.10010517</concept_id>
<concept_desc>Software and its engineering~Scripting languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011039.10011311</concept_id>
<concept_desc>Software and its engineering~Semantics</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{General and reference~Empirical studies}
\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[500]{Software and its engineering~Scripting languages}
\ccsdesc[300]{Software and its engineering~Semantics}

\keywords{R language, delayed or lazy evaluation}

\maketitle
\section{Introduction}

The R programming language is widely used in data science. Unbeknownst to many
of its end-users, function calls have a lazy semantics: arguments are suspended
computations which are evaluated if and when they are needed. \citet{oopsla19b}
provided a thorough observational study of a corpus consisting of 16,707
packages written in R. For the most part, the corpus appears to have been
written without reliance on laziness with the exception of code that leverages
it for meta-programming. This paper argues that laziness should be the exception
in R. We propose to make it a \emph{eager by default, lazy on demand} language
by introducing strictness annotations. The question we wish to answer is whether
it is possible to switch the semantics of a language without causing undue
breakage in the legacy code that is in daily use. This concern is relevant
because, even if programmers don't avail themselves of laziness, it is
conceivable that their code accidentally depends on it. A change in the order of
evaluation of arguments may introduce errors if that code was performing side
effects.

\paragraph{The case for strictness.} Laziness is error-prone, inconsistent
and costly! The combination of delayed evaluation and side-effects in a language
without type annotations is an invitation to subtle programming errors. If a
function has multiple evaluation orders and is called with effectful arguments,
their effects will be observed to happen in various orders. Functional languages
prevent ordering issues by reflecting effects in the type system. R cannot do
this as it is dynamically typed. Instead, libraries routinely add code at the
boundaries of their interface to force a single evaluation order. The design and
use of laziness is inconsistent because there are multiple points where
evaluation is arbitrarily forced. These include right-hand side of assignments
and function returns, neither of which is required in a lazy language.
Furthermore, to support object-oriented programming, R allows both single- and
multiple-dispatch; in order to perform dispatch, arguments must be evaluated
eagerly. Last, there are costs to lazy evaluation. Each argument must be boxed
in a data structure that holds a reference to the expression to evaluate, its
environment and the result of evaluation. Allocating and deallocating these data
structures put pressure on the memory manager. Delayed evaluation further
complicates the work of compilers for the language by hindering optimizations
and increasing the number of indirect calls.

\paragraph{The case for laziness.} The success of a programming language
often comes down to the strength of its ecosystem. With tens of millions of
lines of contributed library code, any change to the core semantics of the
language risks changing the behavior of some library functions. Preserving the
status quo is a pragmatic choice to protect the investment in legacy code bases.
There is also a genuine need for lazy evaluation, it is the building block of
the meta-programming facilities of the language. Unevaluated arguments can be
coerced back to their source code, that code can be modified, and evaluated in
an environment of the programmer's choice. Meta-programming is used to extend
the language and to create embedded domain specific languages. While it is
possible to imagine using macros instead, the number of libraries that use
meta-programming is sufficiently large that it would be non-trivial to refactor
them.

\paragraph{A pragmatic path forward.} How can an entire ecosystem migrate to
a new semantics? A viable migration path should follow the following four
tenets: ({\bf T1}) source code changes to legacy code should be kept to a
minimum; ({\bf T2}) the migration should either be (semi-)automated, and require
limit involvement of legacy developers; ({\bf T3}) the migration should have
measurable benefits; and ({\bf T4}) the migration should be testable with
discrepancies easily attributed to a specific change.
%
%
We propose a migration path that will lead to a mostly strict ecosystem based on
an augmented semantics for R, an performant implementation of that semantics in
the \Rsh compiler, and \lazr a tool for inferring strictness signatures.
Specifically, we propose an approach that follows the above guidelines.
\begin{itemize}
\item[{\bf T1:}] The extensions to the semantics are designed to be
  non-invasive, in our first iteration, only file that have functions requiring
  some of their arguments to be lazy need annotations, and these annotations can
  be added out of line in separate signature files. As the annotation are on
  functions, the need for those will be mostly focused at library interfaces.
  End-user code can remain unchanged. We claim that the behavior most R users
  expect from their code closely aligns to a strict semantics. This change will
  thus not affect their experience.
\item[{\bf T2:}] A tool can leverage the structure of the R ecosystem to infer
  annotations for legacy library code. R packages are hosted in a curated
  repository called CRAN, that repository enforce format and checks on the code
  stored in it. In particular every program has runnable use-cases and tests.
  The can use those to infer signatures for all packages. The inferred signature
  must be validated by a developer (or they can also be deployed and refined
  iteratively).
\item[{\bf T3:}] To evaluate the performance and memory benefits of decreasing
  the laziness of R programs, the an optimizing compiler can be extended to
  support strictness signatures. This will lead to code that performs fewer
  allocations, thus needs less frequent garbage collection passes, and can
  optimize evaluation of arguments by inlining it at the call site.
\item[{\bf T4:}] To test the robustness of inferred signatures to different
  calling contexts, each package can be tested by running the transitive closure
  of its clients and their tests. Programs that crash or departed from their
  expected behavior indicate erroneous strictness annotations.
\end{itemize}

Our long term aim is to propose such a migration path to the R community. In
this paper we propose to evaluate the proposed migration path. We make
the following contributions:

\begin{itemize}
\item We propose \strictr, a non-invasive extension of the R language, where
  optional signature files specify, for individual functions, which of their
  arguments are strict. The proposal is integrated in the R environment and
  compatible with the package loading model. In GNUR, the reference
  implementation of the language, the new semantics is implemented by
  source-to-source rewriting of functions as they created in the interpreter.
\item We implement \lazr, an infrastructure for large-scale inference of
  strictness signatures for legacy libraries. We evaluate \lazr on packages
  hosted in the CRAN repository. For each package \lazr extracts all executable
  code from vignettes, examples and tests, and infers signatures for all
  functions defined by the package. The process is shown to scale to the 500
  most widely used packages in the R ecosystem.
\item We conducted an experiment using the \Rsh optimizing just-in-time compiler
  to evaluate the benefits of unboxing and inlining
  delayed evaluation on a benchmark suite of small computational tasks. We show
  a median \speedupRshStrict speed up on those benchmarks.
\item We evaluate the robustness of the inferred signatures by testing them with
  2,000 packages that are transitive clients of the packages for which
  signatures were inferred. We report 0.3\% error rate, \emph{i.e.}~signatures
  that cause executions to diverge from the reference semantics.
\end{itemize}

Our conclusions are that a semi-automated migration is viable; for community
review we intend to reduce the error rate by folding all clients of packages
together to infer combined signatures.

\paragraph{Availability} Our work is in open source, all experiments are
repeatable and will be submitted for artifact evaluation.

\section{Background}

This section sets the stage by introducing related work and giving a brief
overview of R.

\subsection{Related Work}

There are three clusters of related results: research on adding and removing
laziness in functional languages, research on the R language, and approaches to
language migration.

\paragraph{Call by need}  Functional languages with
a call by need evaluation strategy must contend with memory pressure and
associated performance issues due to allocation of substantial numbers of thunks
(suspended computations)~\cite{transformopt,stricteffective,opteval}. While most
Haskell programs benefit from the strictness analysis pass performed by the
compiler. Due to its conservative nature, this pass misses some opportunities
for optimizations. To recover performance programmers can manually insert
strictness annotations to control evaluation but identifying where to put them
can be challenging. \citet{autobahn} proposed, Autobahn, a tool that
automatically infers strictness annotations using a genetic algorithm. The
approach relies on a dynamic analysis, as it does not approximate and cannot
guarantee termination on all inputs. As the annotations are based on a
heuristic, developers must manually validate their soundness. The authors report
an average 8.5\% speedup (with a maximum speed up of 89\%). \citet{lazyprof}
solve the complementary problem of suggesting laziness annotations for
call-by-value $\lambda$ calculus using a dynamic analysis. They introduce the
notion of laziness potential, a predictor of the benefit obtained by making an
expression lazy. They use this as a guide to insert laziness annotations. They
demonstrate benefits on Racket implementations of Okasaki's purely functional
data structures, monadic parser combinators, and an AI game. The present paper
is similar to Autobahn in that we infer annotations dynamically and we do not
guarantee soundness. Where our work departs from Autobahn is that we use
execution traces to determine strictness. Furthermore, we have to deal with
side-effects and reflective operations, they introduce extra complexity for our
synthesis algorithm.

\paragraph{The R language} \citet{oopsla19b} investigated the design and use of
laziness in R. They provide a detailed account of the language's evaluation
strategy with a small-step operational semantics and an empirical evaluation of
laziness in 16,707 packages. Their study shows that most R code is written
without reliance on, or awareness of, laziness. Out of 388K functions, 83\%
evaluate all of their arguments in a single order across all calls. The authors
found that programmers sometime force evaluation of arguments at the beginning
of a function to protect their code from non-deterministic effects. Only a
single instance of a lazy data structure could be found. The main \emph{raison
d'\^etre} for delayed evaluation seems to be meta-programming. \citet{oopsla20b}
empirically inferred type signatures for functions by dynamically observing the
type of arguments and return values. The authors validated these signatures by
inserting type checking code inside functions and monitor type failures on
client programs. This approach inspired our strictness inference, but types are
easier to check for soundness than strictness. For types, one simply inserts
code that checks that, if an argument is eventually evaluated, it evaluates to
the expected type. For strictness, we have to worry about the interplay of
side-effects and changes to the order of evaluation of arguments. This makes
validation of strictness signatures hard.

\paragraph{Language migration} Changing a language with a large code base
is challenging. No migration has been more fraught than that of Python. Python 3
was released in 2008 with many changes that broke backwards compatibility and no
automated upgrade path. \citet{Agg15} attempted to use statistical machine
learning to convert Python 2 to 3. \citet{Pra20} described a tool for
discovering types in Python programs as a combination of probalistic type
prediction and search-based refinement. Migration was studied in the context of
Java libraries~\cite{Xu19}, Android apps~\cite{Orso20} and C++
applications~\cite{OB20}. A more successful experience is the migration from PHP
to Hack at Facebook. The key to success was a close feedback loop between
language changes and their impact on the ecosystem at large. As all the users of
Hack shared a single source code repository, it was possible to test changes and
develop tools target at relevant usage patterns. One last relevant thread of
work is the migratory typing of \citet{matthias06} where a gradual type system
is added to a variant of the Scheme programming language to enable gradual
migration from untyped to typed code.


\subsection{Laziness and the R Language}

The R language is widely used in data science. R is a vectorized, dynamic, lazy,
functional and object-oriented programming language~\cite{ecoop12}, designed to
be easy to learn by non-programmers and to enable rapid development of new
statistical methods. The language was created in 1993 by~\citet{R96} as a
successor to an earlier language for statistics named S~\cite{S88}.

\paragraph{Functions}
In R every linguistic construct is desugared to a function call, even control
flow statements, assignments, and bracketing. Furthermore, all functions can be
redefined. This makes R both flexible and challenging to compile. A function
definition can include default expressions for parameters, these can refer to
other parameters. R functions are higher-order. The following snippet declares a
function \code f which takes a variable number of arguments, whose parameters
\code x and \code y, if missing, evaluate to \code y and \code{3*x}. The function
returns a closure.
\begin{lstlisting}[style=R]
> f <- function(x=y, ..., y=3*x) { function(z) x+y+z }
\end{lstlisting}\vspace{1mm}
\noindent
Function \code f can be called with no arguments \code{f()}, with a single argument
\code{f(3)}, with named arguments \code{f(y=4,x=2)} and with a variable number
of arguments, \code{f(1,2,3,4,y=5)}. Some functions are written so as to
tolerate missing arguments, to this end the \c{missing(x)} built-in can be used
to check is parameter \code{x} was provided at the call site. Note that in the
above example, \code{x} can have a value and be missing at the same time (because
the default value does not void missingness). A vararg parameter, written
\code{...}, accepts an arbitrary number of arguments, including missing arguments.
A vararg can be materialized into a list with \code{list(...)}. Most frequently
varargs are passed forward to a called function. This enables the function to
expose its callee's interface to the callers without listing callee's parameters
and their default values.

\paragraph{Attributes}
Values can be tagged by user-defined attributes. For instance, one can attach
the attribute \code{dim} to the value \code{x<-c(1,2,3,4)} by evaluating
\code{attr(x,"dim")<-c(2,2)}. Once done, arithmetic functions will treat \code x
as a \code{2x2} matrix. Another attribute is \code{class} which can be bound to
a list of names. For instance, \code{class(x)<-"human"}, sets the class of
\code{x} to \code{human}. Attributes are used for object-oriented dispatch. The
``S3 object system'' supports single dispatch on the class of the first argument
of a function, whereas the ``S4 object system'' allows dispatch on all
arguments. These names refer to the version of the S language which introduced
them. Popular data types, such as data frames, also leverage attributes. A data
frame is a list of vectors with \code{class} and \code{colname} attributes.

\paragraph{Reflection}
R supports reflection and meta-programming. The \code{substitute(e,envir)}
function yields the parse tree of the expression \code{e} after performing
substitutions defined by the bindings in \code{envir}.
\vspace{-1mm}
\begin{lstlisting}[style=R]
> substitute(expression(a + b), list(a = 1)))
expression(1 + b)
\end{lstlisting}
\noindent
This can also be done in native code using the \code{PREXPR} C macro. R allows
programmatic manipulation of parse trees, which are themselves first class
objects. They are evaluated using the \code{eval(e,envir)} function. Environment
on the call stack can also be accessed.

\paragraph{Effects} While R strives to be functional, it has many imperative
features such as assignment to local variables \code{<-}, assignment to
variables in an enclosing scope \code{<<-}, assignment in a programmatically
chosen scope \code{assign()}. R support non-local returns either through
exception or by delayed evaluation of a \code{return} statement. Of course,
there are all sorts of external effects and no monads.

\paragraph{Delayed Evaluation}

The combination of side effects, frequent interaction with C, and absence of
types has pushed R to be more eager than other lazy languages. Strictly
speaking, R's not lazy as it evaluates arguments that it does not need to. Let
us review its design. Arguments to a function are bundled into a thunk called a
\emph{promise}. Logically, a promise combines an expression's code, its
environment, and its value. To access the value of a promise, one must
\emph{force} it. Forcing a promise triggers evaluation and the computed value is
captured for future reference. The following snippet defines a function \code{f}
that takes argument \code x and returns \code{x+x}. When called with an argument
that has the side effect of printing to the console, the side effect is
performed once as the second access to the promise is cached.
\begin{lstlisting}[style=R]
> f <- function(x) x+x
> f( {print("Hi!");2} )
"Hi!"
4
\end{lstlisting}

\noindent
Promises associated to parameters' default values have access to all variables
in scope, including other parameters. Promises cannot be forced recursively,
that is an error. Promises are mostly encapsulated and hidden from user code. R
only provides a small interface for operating on promises:
\begin{itemize}
\item {\bf\small\code{delayedAssign(x,exp,eenv,aenv)}}: create a promise
  with body \code{exp} and binds it to variable \code x (where \code x is a
  symbol). Environment \code{eenv} is used to evaluate the promise, and
  \code{aenv} is used to perform the assignment.
\item {\bf\small\code{substitute(e,env)}}: substitutes variables in \code e
  with their values found in environment \code{env}, returns an
  \code{expression} (a parse tree).
\item {\bf\small\code{force(x)}}: forces the promise \code x. This replaces a
  common programming idiom, \code{x<-x}, which forces \code x by assigning it
  to itself.
\item {\bf\small\code{forceAndCall(n,f,...)}}: call \code{f} with the
  arguments specified in the varargs of which the first \code{n} are forced
  before the call.
\end{itemize}

\noindent
While R does not provide built-in lazy data structures, they can be encoded. R
evaluates promises aggressively. The sequencing operator \code{a;b} will
evaluate both \code a and \code b, assignment \code{x<-a} evaluates \code a, and
\code{return} also triggers evaluation. In addition, many core functions are
strict.


\section{StrictR: R with Strictness Signatures}

We refer to the R language extended with strictness signatures are \strictr to
differentiate with from the GNUR reference implementation. To obtain the
expected semantics, we have implemented an R package, also named \strictr,
which, when loaded, causes strictness signatures to be applied to all loaded
code.

\paragraph{Signature files.}
A signature file contains strictness signatures for functions of one or more
packages. The format is straightforward, a sequence of signature \emph{sig}
such that each function strictness signature is of the form

\[
\mathit{sig}~~::=~~\mathsf{strict}~\mathsf{`package}::\mathsf{function`}~~\langle i, j, k, \dots\rangle
\]

Here {\sf package} is the name of the package in which the function occurs and
{\sf function} is the name of the function. The sequence of integers specify
which argument positions must be evaluated lazily.

One drawback of this external approach is that it does not deal with inner
functions. This is difficult in to do in R because of function objects are
anonymous values. Their ``names'' are binding in some enclosing environment,
bindings that can be overwritten at that. Some packages also dynamically set up
methods for object dispatch in their package load hooks. The dynamic nature of
this operation makes it hard to identify the correct qualified name of the
function. For example, the function \code{zoo::merge.zoo} shown below
conditionally defines its inner function \code{f} first with two parameters and
then redefines it with a single parameter.

\begin{lstlisting}
function(..., all=TRUE) {
    f <- if (any(all)) function(a, ret.zoo=TRUE) # { ... }
         else            function(a, ret.zoo=TRUE) # { ... }
    f <- function(i) # { ... }
}
\end{lstlisting}


\paragraph{Applying signatures.}
To apply signatures in the GNUR interpreter, \strictr performs source-to-source
rewriting of functions as they are loaded. The rewriting is simple, each
function must \c{force} every argument that was not declared lazy. The
implementation uses a feature of R that allows to register callbacks when
packages are loaded. \strictr registers a callback which reads the signature
file in the current directory or on the load path. Then, as functions are
defined \strictr injects code in the function in accordance with the signature.
The injected code checks argument for missingness, and if they are not missing
or if they have a default value, it calls \c{force} on the argument. Signature
files are usually in directory containing one file per package. Providing
signatures in external files avoids the need to modify the source code of
programs. This also enables easy experimentation with different signature
configurations.

An interesting implementation detail is related to signatures are injected.
Earlier approaches mutated the function's body. This resulted in failures.
Investigation revealed that the same function object could be bound with a
different name with different signatures. For instance, in the \code{rlang}
package, \code{is_same_body <<- is_reference} assigns the definition of
\code{is_reference} to \code{is_same_body}. Mutating \code{is_reference} to make
arguments strict inadvertently also makes the function \code{is_same_body}
strict. Further discussion will clarify why this is undesirable. It suffice to
say that \strictr now copies function objects as it rewrites them.

\paragraph{Extended signature.}
As an option, which we do not pursue in this paper, we have implemented an
annotation package for R which allows us to define the following annotation:
\c{@lazy.file} to say that a file defaults to full lazy, \c{@strict.file} to
denote all functions should be strict, \c{@lazy.param} to denote that an
argument must be lazy, \c{@strict.param} for the converse, and \c{lazy(exp)} to
request that an expression be packed into a promise and evaluated lazily. While
these inline annotations allow to deal with inner functions, they require code
source changes. For the rest of the paper we assume only external annotations.


\paragraph{Intrinsic laziness.} When should a function argument be lazy?
We have not found significant (barely any) use of functional programming idioms
related to call-by-need such as infinite data structures. In fact, most code
seem to be written as if R was strict. There is one significant exception to
this. That is when some form of meta-programming will be applied to an argument.
Consider the following definition for an example:
\begin{lstlisting}
 f <- function(a,b) { print(unparse(substitute(a)));  x <- eval(substitute(b));  x+a }
\end{lstlisting}

\medskip
\noindent
A call of \c{f(1+2, 3+4)} creates two promises. The first is accessed by
\c{substitute}, turned into a string by \c{deparse} and printed. The code of the
second is accessed by \c{substitute} and evaluated by \c{eval}. Then expression
\c{x+a} forces the first promise. The second promise is never forced. Both
arguments are intrinsically lazy. Intrinsic laziness is transitive as arguments
are passed from one function to the next. In C code, the argument to
\code{PREXPR} are never strict for similar reasons.

An argument may not be evaluated in all calls to the function. This means the
function function is not strict in that argument. Unless the documentation
dictates that this argument is evaluated in special cases where it is expected
to perform a reflective or effectful operation, we could still evaluate it
without any observable consequence except a performance penalty.


\paragraph{Accidental laziness.} In order to preserve behavior of legacy code
some parameters may be labeled as lazy even if the called function does not
require or expect them to be. An argument that performs a side-effect may have
to be treated as lazy to retain semantics, for instance in the following call,
\c{f(g(),x<-1)}, it is unknown in which order function \c f will evaluates it
argument. Enforcing a strict left-to-right order could lead to an observable
difference in behavior if the call to \c{g()} somehow reads \c{x}. There are two
mitigating factors, writing such code in a lazy language is bad practice, as
small changes in the implementation of \c f may change evaluation order.
Secondly, R has a copy-on-write semantics for vectors and lists, as these are
the most frequently used data types, many updates will not be observable.
Errors and exception are another source of effect inside promises. They can
either stop the program execution or be captured by an enclosing exception
handler.

Some functions occurring in a promise can make evaluation of the promise
sensitive to its position on the call stack, and strict evaluation would be
observable. Functions \code{as.environment} and \code{pos.to.env} when invoked
with argument \code{-1} return the environment of the caller. Forcing this
argument promise eagerly on function entry could result in a different result if
the promise was being passed down to callees for evaluation. Note that if the
function's documentation does not make any commitment about the frame in which
this argument will be evaluated, this code will be susceptible to breakage due
to change in the function's implementation.

Vararg arguments may have to be lazy. Assigning a single strictness annotation
to $\dots$ is tricky because a function can have different strictness behavior
for the individual elements of $\dots$. One solution is to treat the function
strict in $\dots$ if it is strict in all of its constituents. However, this
signature may still not be unique. Unlike normal argument promises, promises
inside $\dots$ are not packaged in a new promise but rather forwarded as-is to
callees. A function's callees may use metaprogramming on the promises inside
$\dots$ even if the function itself does not . Furthermore, a $...$ passed to a
callee could be forwarded further down resulting in a long chain of functions
having access to the same argument promises. All these functions in the chain
can directly affect these arguments. The presence of missing arguments inside
$...$ introduces another wrinkle.

\paragraph{Orders of evaluation} A design choice we faced was to select
in which order to evaluate a strict function. As R has named arguments functions
can be invoked with a permutation of their defined parameters. The question is
thus what is most natural? From the point of view of a library, any order strict
order is equivalent to any other. From the point of view, of clients there is
likely an expectation that arguments are evaluated left-to-right. For technical
reason, \strictr evaluates strict arguments in definition order. We are
experimenting with the alternative in our \Rsh implementation. We do not have
sufficient experience to determine if one is superior.


\section{Inferring Strictness with LazR}

This section describes how to infer strictness annotations at scale.

\subsection{Infrastructure}

\lazr is an analysis pipeline for inferring strictness annotations in legacy R
libraries at scale. It builds on the \rdyn package which extends the GNUR
virtual machine version 4.0.2 with hooks for registering
callbacks~\cite{oopsla19b}. The analysis pipeline starts with setting up a
Docker image that includes all the dependencies for installing analysis code and
R packages from CRAN~\cite{ligges2017} and Bioconductor~\cite{bioc}. This
provides a reliable reproducible setup across the two machines. Next, we mirror
CRAN and Bioconductor repositories and install their R packages. This is
followed by generation of execution traces from a dynamic analyzer running
inside an instrumented R virtual machine. These traces are analyzed to generate
tabular data files and strictness signatures. Our analysis pipeline is managed
by a Makefile which has rules for every step. This makes it easy to administer
the experiments on multiple machines. Whenever possible, we parallelize the
steps using GNU parallel~\cite{tange2011a}. Experiments were performed on two
Intel Xeon 6140, 2.30GHz machines with 72 cores and 256GB of RAM each.

\subsection{LazR} \label{subsection:lazr}

The low-level \rdyn allows registering callbacks with raw R objects at various
points inside the R interpreter. Extracting meaningful information from these
objects requires handling many subtleties arising from the intricacies of R's
execution model. These details are surprisingly hard to get right.

\lazr provides a layer of abstraction on top of the event framework. It allows
creating tracers to which callbacks can be attached, and intercepts low-level
events to invoke the corresponding tracer's callbacks. Rather than exposing raw
R object, it exposes \emph{model} objects. These model objects abstract the raw
R objects and provide a consistent introspection interface. Model objects also
provide unique identities to anonymous objects. This uniqueness guarantee
enables downstream clients to not worry about to memory manager recycling
addresses. The model objects are reference counted so they can still be
reclaimed. Cycles are dealt with the notion of a primary owner; an object's
primary can release that object. This design eases expressing complex object
dependencies without memory leaks. This greatly simplifies the handling of
promises, first class environments and function calls.

During analysis, \lazr keeps track of logical time, from program entry to exit,
time is incremented on every event. Every model object records the birth and
death of the raw R object being modeled. For environments, the model object also
keeps track of last read and write times. For promises, start and end of forcing
are recorded. This information is used to classify side-effects.

For performance, model objects are cached in a table keyed by the R object's
address. Cache are updated on allocation and deallocation events. This prevents
duplication of model objects when the same R object is encountered multiple
times. The call stack is modeled together with the promises that are under
evaluation. This helps identify if an event, say a side-effect, occurs inside a
promise. Furthermore, as R uses \emph{longjmp} to do non-local returns, \lazr
deals with such events by calling the exit callbacks of interrupted calls and
promises on the stack. Environment and function names are also modeled. Getting
fully qualified function names dynamically is challenging in R because package
namespaces are first class environments that are constructed piecemeal and all
functions are by default anonymous and may be bound to any name in their lexical
scope. \lazr handles this by assigning names to environments on package load
events and checking on every write if a function is being bound to a name.
Functions can be nested to arbitrary depths in which case, function model object
are linked to reflect their parent-child relationship.

During execution, \lazr collects information about function calls, arguments,
side-effects, and reflective environment access. from the model objects provided
by the following event: \emph{function entry and exit}, \emph{promise evaluation
entry and exit}, \emph{variable reads and writes}, \emph{promise value and
expression reads}, and \emph{function lookup}. This information is stored in
compressed tabular format using R's \c{fst} library.

For signature generation, we use a custom R script that summarizes argument
evaluation data per function from the tables obtained during tracing and
generates signatures for different strictness configurations. We output one file
per package with signatures for all top-level functions of that package.
The execution traces we generate from our corpus are 1.2TB in size. To analyze
them for insights and data visualization, we designed a simple map-reduce style
pipeline. Each analysis is split in 4 phases. The first phase is the
\emph{reduce} phase in which we map an R function on the execution trace of each
program to get a partial summary. Next is the \emph{combine} phase in which we
concatenate the partial summaries obtained from the \emph{reduce} step. Then,
the \emph{summarize} phase summarizes the concatenated partial summaries to
generate a table with a complete summary. At this point, the summary file is
less than 100MB in size. These steps are performed for multiple analyses to get
as many summary files. Finally, in the \emph{report} phase we analyze these data
files in an RMarkdown notebook to generate data points, graphs, and tables for
inclusion in the paper.

\subsection{Corpus}

\begin{wraptable}{r}{7cm}
  \vspace{-3mm}
  \small
  \caption{Corpus}\label{table:corpus}
  \vspace{-3mm}
  \begin{tabular}{lrrrl}
    \toprule
    &\bf Tests&\bf Examples&\bf Vignettes&\\
    \midrule
    \multirow{2}{*}
    {Scripts}&5.8K&20.2K&631&\it Corpus\\
    &9.8K&41.1K&1.7K&\it Client\\\hline
    \multirow{2}{*}
    {LOC}&406.4K&207.0K&48.7K&\it Corpus \\
    &751.2K&348.8K&112.3K&\it Client \\
    \bottomrule
  \end{tabular}
\end{wraptable}%%

We selected corpus packages and client programs from CRAN and Bioconductor, two
official package repositories for R. CRAN and Bioconductor have 17,388 and 3,344
packages each, of which, we were able to install 17,142 CRAN and 2,733
Bioconductor packages. Some packages could not be installed because of missing
native dependencies and compilation errors. We discard those packages. Code in
those repositories is curated by subjecting it to a battery of quality checks.
Packages have runnable code in the form of tests, examples, and vignettes.
Vignettes are typically long examples which demonstrate a packages
functionality.

We synthesized signatures for functions from 500 packages. The criterion was to
select packages which had the most clients, \emph{i.e.}, packages which are the
most widely used in the ecosystem. This requirement will prove handy for
evaluation. The chosen packages have a total of 15,362 dependent client
packages, ranging from maximum 2,669 dependents for \emph{ggplot2} to minimum 5
for \emph{spatstat.linnet} with an average 125.4 dependents. The selected 500
packages have 2.2M lines of R code and 2.7M lines of native code. For
synthesizing signatures for their functions, we analyzed the execution traces
obtained from their examples, tests, and vignettes. Table ~\ref{table:corpus}
gives the number of scripts of each kind that were run and lines of code
exercised.

\subsection{Inference}
\begin{wraptable}{r}{8cm}
  \vspace{-3mm}
  \small
  \caption{Package Size} \label{table:packsize}
  \centering
  \begin{tabular}{lr}
    \toprule
    \bf Functions&\bf Packages\\
    \midrule
    1--25&148\\
    26--50&98\\
    51--75&52\\
    76--100&33\\
    101--150&54\\
    151--200&34\\
    201--250&28\\
    \bottomrule
  \end{tabular}
  \quad
  \begin{tabular}{lr}
    \toprule
    \bf Functions&\bf Packages\\
    \midrule
    251--300&16\\
    301--400&14\\
    401--500&7\\
    501--600&5\\
    601--700&1\\
    701--800&4\\
    801--900&2\\
    \bottomrule
  \end{tabular}
\end{wraptable}

We generate signatures for 50,435 functions from 500 packages. These are
top-level package functions. We ignore anonymous and inner functions.
Table~\ref{table:packsize} shows the distribution of these functions across
packages. We observe that 148 packages have 25 functions or less. As expected,
there is a steady decrease in packages with more functions. There are 12
packages with more than 500 functions. Package \emph{spatstat.geom} has the
maximum number of functions, 886.

We observe 137.2M calls to these functions. Figure ~\ref{fig:callDist} shows the
number of distribution of calls across functions called in the synthesis
phase. 49.5\% functions are called more than 10 times. 16.4\% functions are
called only once, leading to low coverage. These functions are spread across 414
packages.

\begin{figure}[!h]
  \centering
  \input{graphs/call_dist.tex}
  \caption{Call Distribution}
  \label{fig:callDist}
\end{figure}

We observe 294.45M arguments created in our execution traces. Of those 3.9M are
missing, 18.9M are $...$ arguments, and 271.6M are promises. These arguments
correspond to 185.9K parameter positions of the 50,435 functions for which we
generate signatures. Figure ~\ref{fig:paramDist} shows the distribution of these
parameters per function.

\begin{figure}[!h]
  \centering
  \input{graphs/param_dist.tex}
  \caption{Parameter Distribution}
  \label{fig:paramDist}
\end{figure}

7.3\% functions have 0 parameters, 19.6\% have 1, and 5.0\% have over 10. There
are 15 functions with over 50 parameters that come from 10 packages.
\c{ComplexHeatmap::pheatmap} (51), \c{network::plot.network.default} (52),
\c{rpart.plot::get.layout} (53), \c{sna::gplot} (54), \c{Hmisc::latex.default}
(55), \c{VennDiagram::draw.quintuple.venn} (57) \c{pROC::plot.roc.roc} (58),
\c{rpart.plot::draw.node.numbers} (60), \c{gplots::heatmap.2} (63),
\c{Hmisc::event.chart} (66), \c{ComplexHeatmap::Heatmap} (83),
\c{ggplot2::theme} (95), \c{ergm::control.ergm} (117), \c{rpart.plot::prp}
(119), and \c{rpart.plot::check.if.dot.arg.supported.by.rpart.rules} (122) with
the highest number of parameters.

Now, we turn our attention to the algorithm used by \lazr to infer strictness.
As discussed in section \ref{subsection:lazr}, \lazr uses execution traces to
synthesize strictness signatures. Execution traces tell us if an argument
\emph{(a)} is evaluated, \emph{(b)} is passed to a $...$ parameter, \emph{(c)}
is metaprogrammed, \emph{(d)} performs a non-local effect, and \emph{(e)}
accesses parent environment reflectively. \lazr merges this information from all
execution traces to get a summary of operations for a function parameter
position. It uses this summary decide if an argument can be evaluated eagerly
and generates strictness signatures. The signatures also dictate the order of
evaluation of arguments.

Because of the difficulty in assigning a unique strictness signature, $...$
arguments are always lazy. Meta-programmed arguments are also lazy as
meta-programming relies on unevaluated argument text provided by a promise. The
remaining operations are sources of \emph{accidental laziness}. We could decide
to unevaluated, effectful, and reflective arguments lazy to preserve the
semantics of legacy code. Or, we could make them strict to get rid of more
promises at the risk of breaking code. The impact of this choice is not clear
upfront. Hence, \lazr synthesizes multiple strictness signature
``configurations`` to facilitate this assessment. It is worth noting that making
arguments lazy if they are side-effecting has the potential to make everything
lazy because it is dependent on how a client invokes the API. \lazr only makes
the parameter lazy if an argument has performed a side-effect or reflective
operation in the programs it has run. Including more programs will make more
arguments lazy.

Now, we take a detailed look at the different sources of laziness.

There are XXXX $...$ parameters. We unconditionally treat them lazy.

\subsubsection{Metaprogramming}
For tracking metaprogramming, we look at uses of \code{substitute} on arguments
from R code and \code{PREXPR} macro on promise objects from C code. We observe
substitute called on XXX arguments from XXXX parameters of XXXX functions.
\code{PREXPR} was called on XXX arguments from XXXX parameters of XXXX
functions.

For an in-depth discussion on the patterns of use of \code{substitute}, we refer
the reader to \citet{oopsla19b}. We continue with the exploration of the use of
\code{PREXPR} for metaprogramming, since that is not addressed in
\cite{oopsla19b}.

We observe that 




\subsubsection{Unevaluated Arguments}
Of the 294.45M total arguments in our corpus, 30.4M argument promises were not
evaluated. They correspond to 52,083 parameters of 26,398 functions from 473
packages. These functions are non-strict in the corresponding parameters.

Based on argument evaluation, we can classify parameter positions into three
categories.\always parameters are those whose arguments are evaluated in all
calls. \sometimes parameters are those whose arguments are evaluated at least
once but not always. \never parameters are those whose arguments are never
evaluated. Table~\ref{table:argeval} shows the number and proportion of
parameters that belong to these categories.

\begin{table}[!h]
  \vspace{-3mm}
  \caption{Argument Evaluation}\label{table:argeval}
  \vspace{-3mm}
  \begin{tabular}{lr|lr|lr}
    \toprule
    \textbf{Type}&\multicolumn{2}{c}{\textbf{Parameters}}&\multicolumn{2}{c}{\textbf{Functions}}&\textbf{Packages}\\
    \midrule
    Always&144565&73.51\%&48456&96.08\%&490\\
    Sometimes&16411&8.35\%&7070&14.02\%&410\\
    Never&10637&5.41\%&5907&11.71\%&405\\
    \midrule
    Sometimes*&15130&7.69\%&6609&13.1\%&406\\
    Never*&9251&4.7\%&5121&10.15\%&400\\
    \bottomrule
  \end{tabular}
\end{table}

Majority of parameters are \always parameters, suggesting that arguments passed
to functions are evaluated in most of the cases. This is followed by 8.35\%
\sometimes parameters. Their presence indicates use of metaprogramming or
unexplored control flow paths in the function. Lastly, we have 5.41\% \never
arguments whose presence indicates lack of coverage, metaprogramming, or dummy
parameter. The \textbf{Functions} field gives the number of functions with
\always, \sometimes, and \never arguments. The same function can appear in
multiple columns since different parameters can have different evaluation
classification. The \textbf{Packages} field of Table~\ref{table:areval} tells us
that \never and \sometimes functions are spread across many packages.


\sometimesStar and \neverStar in Table~\ref{table:argeval} are the number of
\sometimes and \never cases without metaprogrammed. The different is small which
suggests that metaprogramming is not the primary reason for arguments remaining
unevaluated. Turning to the number of calls, we find that 78.33\% of functions
with \never parameters are called more than once. This suggests that a lack of
call diversity could be one of factors for \never arguments' existence. With
better call diversity, the \never parameters will turn into \sometimes.

\paragraph{Qualitative Analysis}

We analyzed a sample of functions with \sometimes and \never parameters to
identify usage patterns.

First, we look at \sometimes parameters. A common patter occurring in 30
packages is the following definition of \code{\%||\%} function.

\begin{lstlisting}
lazyeval::\%||\% <- function(x, y) if(is.null(x)) y else x
\end{lstlisting}

This function evaluates its second argument \code{y} only if \code{x} is
\code{NULL}. This makes \code{y} a \sometimes parameter. This pattern suggests
that \code{y} is a \sometimes parameter for a reason and should not be evaluated
unless needed. However, there are other functions with multiple paths where
evaluating the \sometimes argument is expected to be benign. For example, in
\code{bayesplot::is_whole_number} function, the \code{tol} argument is only
evaluated when \code{x} is a numeric value. I

\begin{lstlisting}
bayesplot::is_whole_number <- function(x, tol = .Machine$double.eps) {
    if (!is.numeric(x)) { FALSE } else { abs(x - round(x)) < tol }
}
\end{lstlisting}


Another pattern occurring in 4 packages is the definition of
\code{on_package_load}.

\begin{lstlisting}
glue::on_package_load <- function(pkg, expr) {
    if (isNamespaceLoaded(pkg)) { expr }
    else {
        thunk <- function(...) expr
        setHook(packageEvent(pkg, "onLoad"), thunk)
    }
}
\end{lstlisting}

Here, if package \code{pkg} is not loaded, the \code{expr} argument's evaluation
is delayed until the package's \code{onLoad} event occurs. In some executions,
we see the \code{expr} argument being evaluated if package \code{pkg} is loaded
and in other iterations, we don't. The way this code is written suggests that
\code{expr} should not be evaluated strictly.

S3 generics result in many \sometimes and \never parameters. These functions
dynamically dispatch to a specific implementation with the same name based on
the first argument's class. In this case, the first argument is always evaluated
but the remaining arguments might not be needed by the specific method. Across
all executions, we observed that \code{n} and \code{m} are evaluated sometimes
but \code{r} is never evaluated.

\begin{lstlisting}
abind::acorn <- function(x, n=6, m=5, r=1, ...) UseMethod('acorn')
\end{lstlisting}


Next, we turn our attention to \never parameters.

The most common case is when an argument is not used in some branch of the
function. Due to lack of call diversity, the branch in which the argument is
used is never taken and the parameter is classified as \never. For example,
\code{discretize} function of package \code{actuar} only uses \code{xlim} if
\code{from} and \code{to} parameters are missing.
\begin{lstlisting}
actuar:::discretize <- function (cdf, from, to, ..., xlim = NULL) {
    ...
    if (missing(from)) from <- xlim[1];
    if (missing(to)) to <- xlim[2];
    ...
}
\end{lstlisting}


Another pattern leading to \never parameters is when a function is called with a
certain interface even if it does not use those arguments. R calls a package's
\code{.onLoad} function with arguments \code{libname} and \code{pkgname} when
the package is loaded. The \code{.onLoad} hook of \code{assertive.base} package
ignores them.
\begin{lstlisting}
assertive.base::.onLoad <- function(libname, pkgname) {
    options(assertive.severity = "stop")
}
\end{lstlisting}

The \code{proxy} package defines over a dozen methods with the interface
\code{function(a, b, c, d, n) ...} that implement different proximity metrics by
using only a subset of the arguments.
This also happens in method dispatch when the generic method defines a parameter
which is not used by the specific method. For example \code{bit64} package
defines \code{unipos} generic method with a parameter \code{incomparables} which
is not used by its only concrete implementation \code{unipos.integer64}


Sometimes arguments don't need to be used by design.
The \code{tail} operation in package \code{dbplyr} is not defined for
\code{tbl_lazy} objects. So the function throws an error when called without
using any of its arguments.
\begin{lstlisting}
dbplyr::tail.tbl_lazy <- function(x, n = 6L, ...) {
    stop("tail() is not supported by sql sources", call. = FALSE)
}
\end{lstlisting}

Sometimes packages implement a specialized compatible wrapper.
\code{jsonlite} package implements \code{stop} function with the same interface
as R's \code{base} package's \code{stop} function but ignores its \code{call.}
argument.
\begin{lstlisting}
jsonlite::stop <- function(..., call. = FALSE) {
    base::stop(..., call. = FALSE)
}
\end{lstlisting}

\never parameters can also represent an erroneous condition that would not
happen in a correct program. In \code{codetools} package, function
\code{checkSymOrString} fails if the argument does not have the correct type. In
all the calls we observed, the \code{signal} argument was not used because
\code{e} had the correct type.
\begin{lstlisting}
codetools::checkSymOrString <- function(e, signal = stop) {
    type <- typeof(e)
    if (type == "symbol" || type == "character") e
    else signal("not a symbol or string")
}
\end{lstlisting}

\subsubsection{Reflection}

R allows reflective access to parent scope through \code{as.environment} and
\code{pos.to.env} functions when called with argument \code{-1}.
They return the environment of the caller with respect to call in which they are

evaluated. Consider the following example in which function f is called with the
same argument \code{as.environment(-1)} for both \code{x} and \code{y}
parameters. The first argument \code{x} is evaluated immediately inside
function \code{f} and the second argument \code{y} is evaluated inside the
\code{id} function. \code{x} evaluates to the environment of the parent of
\code{f} which is the \code{global} environment, whereas \code{y} evaluates to
the environment of \code{f} which is the parent of \code{id} inside of which
\code{y} is evaluated.

\begin{lstlisting}
id <- function(a) a
f <- function(x, y) { x; id(y); }
f(x = as.environment(-1), y = as.environment(-1))
\end{lstlisting}

There are two points to note here. First, the strictness of \code{f} with
respect to \code{x} and \code{y} depends on how \code{f} is called. Second,
\code{f} will now be lazy in argument \code{y}, otherwise we will end up
evaluating inside \code{f}. Erroneously evaluating \code{y} strictly would
result in an incorrect environment, but not an error, which could turn into a
debugging nightmare.

\code{as.environment} is internally implemented using \code{pos.to.env} so the
two functions have same semantics when called with \code{-1} as the argument.

It is interesting to note that there are other functions providing reflective
access to call stack frames such as \code{parent.frame}, \code{sys.frame}, etc.
However, these take into account the current evaluation environment to identify
the parent caller. A promise evaluates the argument expression inside the
caller's environment. So, a call to \code{parent.frame()} directly inside the
argument will use the caller's environment to identify the parent dynamic scope.
This makes its result independent of the point at which the promise is
evaluated.

Another wrinkle introduced by this setup is that it can transitively affect the
strictness of other function arguments. Imagine \code{f} is called from \code{g}
as shown below.

\begin{lstlisting}
g <- function(u, v) {
    f(u, v)
}
g(as.environment(-1), as.environment(-1))
\end{lstlisting}

Clearly, in this case we have to make \code{g} non-strict in \code{u} and
\code{v}. Their results depend upon how they are evaluated inside \code{f}.

We identified 2710 arguments which directly call \code{as.environment(-1)} and
\code{pos.to.env(-1)} in our corpus. They correspond to 2 parameters from 2
functions, \code{R.oo::.getFunctionByName}, and \code{backports:::get0}.

\code{R.oo:::.getFunctionByName} is a private function of \code{R.oo} package
which searches for a function by name in different scopes, configured by its
arguments. Its fourth parameter, \code{callEnvir}, has a default value of
\code{as.environment(-1)}. It is called 2707 times. The relevant part of its
definition is that \code{callEnvir} is evaluated by assigning it to
\code{envirT} before it is passed down to the \code{exists} function.

\begin{lstlisting}
function(name, where = c("ns", "search", "ns*"),
         envir = NULL, callEnvir = as.environment(-1L),
         class = "function", mustExist = TRUE, ...) {
    ...
    envirT <- callEnvir
    if (exists(name, mode = "function", envir = envirT, inherits = TRUE))
    ...
}
\end{lstlisting}

\code{backports::get0} is a private function of \code{backports} package which
looks up a variable in a scope, similar in spirit to
\code{R.oo:::.getFunctionByName}. This function is called 3 times, always with
the default value \code{pos.to.env(-1)} for \code{envir} argument. Unlike
\code{R.oo:::.getFunctionByName}, \code{backports:::get0} passes \code{envir}
unevaluated to \code{mget}. \code{mget} in turn evaluates \code{envir} and looks
up variable referred to by \code{x} in \code{envir}. Clearly, with the default
value of \code{envir}, lookup will happen in the environment of
\code{backports::get0} which only has bindings for its parameters. What makes
this work is that it is only called from the top-level, with the argument
\code{inherits} set to \code{TRUE}. This causes \code{mget} to search
recursively in enclosing scopes beginning from \code{envir} until lookup
succeeds in the \code{global} environment used for top-level bindings.

\begin{lstlisting}
function (x, envir = pos.to.env(-1L), mode = "any",
          inherits = TRUE, ifnotfound = NULL)  {
    ....
    mget(x[1L], envir = envir, mode = mode,
         inherits = inherits, ifnotfound = list(ifnotfound))[[1L]]
}
\end{lstlisting}

Calls to \code{R.oo:::.getFunctionByName} result in transitively making 1821
argument lazy. They correspond to 18 parameters from 15 functions of 3 packages.
We manually analyzed these cases but found that none of these functions pass
their arguments containing calls to \code{as.environment(-1)} or
\code{pos.to.env(-1)} to \code{R.oo:::.getFunctionByName}. They are identified
as lazy because our dynamic analyzer is conservative. When a reflective call
happens from an argument promise, it taints all the function arguments on the
stack. This has the effect of making more arguments lazy than needed.

\code{backports::get0} is invoked from the top-level so it does not result in
spurious transitive laziness.

\subsubsection{Side-Effects}

\begin{table}
  \vspace{-3mm}
  \small
  \caption{Effects} \label{table:effects}
  \centering
  \begin{tabular}{lllll}
    \toprule
    \textbf{Effect}&\textbf{Count}&\textbf{Parameters}&\textbf{Functions}&\textbf{Packages}\\
    \midrule
    L&3739631&5539&3619&358\\
    D&1069746&2972&2599&319\\
    A&236985&510&486&109\\
    R&1172&27&24&10\\
    E&6&6&6&3\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}
  \vspace{-3mm}
  \small
  \caption{Effect Sequence} \label{table:effectseq}
  \centering
  \begin{tabular}{lll}
    \toprule
    \textbf{Effect Sequence}&\textbf{Argument \%}\\
    \midrule
    (L+D+)+&40.35\%\\
    L+&29.75\%\\
    D+&10.25\%\\
    (L+A+)+&6.96\%\\
    (D+A+)+D+&3.23\%\\
    A+&2.48\%\\
    (L+D+)+L+&1.69\%\\
    (D+A+)+&1.42\%\\
    (L+D+)+(L+A+)+(L+D+)+&0.99\%\\
    (L+D+)+A+&0.5\%\\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Summary}

Table~\ref{table:strictdist} presents a summary of the distribution of
parameters, functions, and packages that correspond to unevaluated, effectful or
reflective arguments. Row \#0 tells that there are 128.3K parameters from 44.4K
functions whose arguments are evaluated across all calls and they don't perform
any effect or reflective operation. Similarly, row \#7 tells us that 25
parameters from 24 functions are not evaluated in at least one call, but whey
they are evaluated, they perform a side-effect and a reflective operation.
Similarly, row \#4 tells us that 27.1K parameters from 11.3K functions are never
evaluated. A careful study of these rows yields the following insights. First,
arguments passed to majority of parameters, 65.25\%, are always evaluated and
don't perform any side-effects or reflective operations. So, they can be made
unconditionally strict . Of the remaining parameters, only unevaluated arguments
correspond to 13.76\% parameters, followed by only side-effecting arguments to
4\% parameters, and only reflective promises to 0.07\% parameters. The remaining
combinations amount to less than a percent each. It is important to note that a
function can appear in multiple rows as different parameters can belong to
different categories. Same reasoning applies to packages. Another interesting
pattern in the data is that arguments performing reflective operations
(alternate rows \#1, \#3, \#5, \#7) come from relatively few functions and
packages.

\begin{table}
  \vspace{-3mm}
  \small
  \caption{Strictness Distribution} \label{table:strictdist}
  \centering
  \begin{tabular}{lcccr|lr|lr}
    \toprule
    \#&\bf Unevaluted & \bf Side-Effecting & \bf Reflective & \multicolumn{2}{c}{\textbf{Parameters}} & \multicolumn{2}{c}{\textbf{Functions}}& \bf Packages\\
    \midrule
    0&\xmark{}&\xmark{}&\xmark{}&128305&65.25\%&44377&85.93\%&489\\
    1&\xmark{}&\xmark{}&\cmark{}&134&0.07\%&124&0.24\%&47\\
    2&\xmark{}&\cmark{}&\xmark{}&7871&4\%&5805&11.24\%&399\\
    3&\xmark{}&\cmark{}&\cmark{}&408&0.21\%&385&0.75\%&93\\
    4&\cmark{}&\xmark{}&\xmark{}&27050&13.76\%&11333&21.95\%&453\\
    5&\cmark{}&\xmark{}&\cmark{}&13&0.01\%&12&0.02\%&11\\
    6&\cmark{}&\cmark{}&\xmark{}&1213&0.62\%&813&1.57\%&199\\
    7&\cmark{}&\cmark{}&\cmark{}&25&0.01\%&24&0.05\%&15\\
    \bottomrule
  \end{tabular}
\end{table}

An important detail in this summary is that includes contribution of
side-effects and reflective operations performed by R's \emph{base} package and
other user packages not part of our corpus. This is because arguments are also
transitively involved in side-effecting or reflective operations. The numbers
provided in this table are upper-bounds, we over count the number of arguments
transitively involved in effects and reflective operations because our inference
algorithm is conservative.

\subsection{Orders of Evaluation}

The argument evaluation orders observed for a function depend on its
implementation and the control-flow paths exercised by its inputs. In this work
we ignore this evaluation order. For evaluation robustness, we choose the
definition order in the synthesized signatures. For assessing performance, the
\Rsh just-in-time compiler uses the call order, i.e., the order in which
arguments are passed to the function at the call site.

Our notion of strictness departs from that of ~\citet{oopsla19b}. According to
them, a function is strict if it evaluates all of its argument in a single
pre-ordained order.

\AG{add evaluation orders and contrast with side effects to assess impact.}
%%the function and choose the definition order.
%%Figure~\ref{fig:force_order} shows the number of evaluation orders of the
%%functions in our corpus. XX(XX\%) functions have a single evaluation order. Out
%%of those, XX functions evaluate all of their arguments. Evaluation orders
%%greater than 5 are rare and are found only in XX functions.


\section{Compile the Lazy Away}

In this section we report on our experiments to evaluate the implications of
eagerness on an implementations of R. To that end we modified \Rsh, a just-in-time
compiler for the language. \Rsh is based on the GNU R reference implementation
and introduces an additional two-tiered compilation strategy. The
first tier is realized by a naive bytecode interpreter, the second tier
by an optimizing native compiler. The compiler employs, among many other
optimizations, speculative inlining of R closures and promises \citep{dls19,
oopsla20c}.
The reason for choosing \Rsh as the target for our
experiments is, that it allows us to better evaluate the impact of lazyness. In
\Rsh we can both measure the impact on an interpreter with few optimizations
applied to the bytecode and an optimizing compiler, that already does its best
eliding promises as long as the default semantics allow it.
To conduct our evaluation, we changed the first-tier
compiler to eagerly evaluate all arguments at all call-sites, except for a
manually curated list of exceptions.
In the following we will refer
to this modified implementation as \Rshstrict.

Our main hypothesis regarding performance is that eager semantics lead to faster
execution of R programs. This hypothesis might seem unexpected to some readers,
as call-by-need is sometimes used to avoid unnecessary computation in a program.
On the other hand, delaying computations is more complex to implement and we
observed it to obstruct performance in two ways: First, it leads to more
allocations of promises used to represent the delayed computation. Second, in
combination with effects potentially originating from promises, it obstructs
more advanced compiler analysis and optimizations. Especially the later point
means that we expect the hypothesis to hold even for a just-in-time compiler,
that uses advanced optimizations.
In particular, we pose the following predictions:
(1) eager semantics should improve performance of most benchmarks for both tiers
of \Rsh; (2) a significant portion of the speedup is due to reduced garbage
collection pressure; (3) and there is an additional speedup due to improved compiler
optimizations. In the following we will present our evidence in support of all
three predictions.

We evaluate the effects of our modifications on the Ř benchmark suite.
To ease the discussion, the results are presented on a representative subset of
the suite which includes one variant of
each benchmark. As should be no surprise given the results presented so far,
only a handful of functions, such as
\lstinline{tryCatch} had to be kept lazy for all the benchmarks to compute
the correct results.

\paragraph{Methodology}

All of the following experiments are run on a dedicated benchmark machine, with
all background tasks disabled. The system features an Intel i7-6700K CPU, stepping 3,
microcode 0xe2 with 4 cores and 8 threads. The system has 32 GB of RAM and is
running Ubuntu 18.04 on a 4.15.0-136 Linux kernel. For ease of use, experiments
are built as OCI compliant containers, based on Ubuntu 20.04, and executed on
the Docker runtime 20.10.5, build 55c4c88. We verified the overhead introduced by
the containerization to be uniform. All measurements are taken repeatedly and we
keep a historical record to spot instable behavior. This lead us to exclude the
\lstinline{convolution} benchmark from the suite, which appears to have a
bi-modal performance profile, likely caused by the llvm backend of \Rsh.

Performance measurements are gathered by running $t_e$ invocations of \Rsh on
each benchmark. Within each invocation we measure the execution time of $t_i$
in-process invocations. For each invocation the first 5 in-process iterations
are discarded, to exclude warmup behavior. Agregate numbers are reported as the
speedup over the arithmetic mean of the execution times. Multiple speedup
numbers are averaged with a geometric mean. To establish a baseline we measured
the speedup of \Rsh over GNU R, on our selection of the benchmark suite with
$t_e = 1, t_i = 15$ and found a mean speedup of \speedupRsh, ranging between
\speedupRshMin and \speedupRshMax.

\paragraph{Speedup}

\begin{figure}[h]
  \centering
  \input{graphs/rshStrictPerf.tex}
  \vspace{-1cm}
  \caption{Speedup of \Rshstrict}
  \label{fig:speedup}
\end{figure}

First, we compare \Rsh against \Rshstrict. This experiment estimates the end-to-end
improvement on performance, that a change to eager semantics in the R language
would have on \Rsh. The execution times were measured with $t_e = 4, t_i = 25$.
\autoref{fig:speedup} shows a boxplot for the execution times of \Rsh-strict,
normalized to \Rsh. Overal, we observe a mean speedup of
\speedupRshStrict, ranging from \speedupRshStrictMin to \speedupRshStrictMax.
For \speedupRshStrictSignificant out of \benchmarkSuiteSize benchmarks we measure a significant increase in performance.
%
\begin{figure}[h]
  \centering
  \input{graphs/rshStrictPerfBC.tex}
  \vspace{-1cm}
  \caption{Speedup of \Rshstrict without optimizations}
  \label{fig:speedup-bc}
\end{figure}
%
Then, we repeated the performance experiment, but with the second tier
optimizer completely disabled. Since this variant executes overal \rshBCSlowdown
slower, we chose to only run with $t_e = 1, t_i = 15$.
The results are presented in \autoref{fig:speedup-bc}. We found that the bytecode
interpreter also gains a speedup of \speedupBCRshStrict, ranging from
\speedupBCRshStrictMin to \speedupBCRshStrictMax.
%
Thus, we conclude that in our benchmark suite both a naive interpreter, as well as a speculatively
optimizing native compiler achieve better performance on a strict dialect of R.
Even though the speedup is very similar in numbers, the reasons seem to be quite
different at times. We'll get back to that point in the discussion at the end of
this section.

\paragraph{Garbage Collection}

\begin{figure}[h]
  \centering
  \input{graphs/rshStrictPerf.tex}
  \vspace{-1cm}
  \caption{Time spent in GC}
  \label{fig:gc-time}
\end{figure}

Even an optimizing compiler has to allocate many promises for R
code, as often times, they cannot be eliminated entirely.
Thus we expect a significant portion of the speedup to originate from
the reduced allocation rate. We measured the time spent in garbage collection
and as can be seen in \autoref{fig:gc-time}, indeed a significant reduction occurs.
These numbers have to be taken with a grain of salt. The GNU R garbage
collector, which is reused in \Rsh, has a fairly slow allocation path, which
includes mutating a doubly-linked list. Therefore, some portion of the speedup
is due to the saved time in the allocation of promises, which is not counted.
Therefore, these numbers underestimate the effect on memory management overhead.
%
\begin{figure}[h]
  \centering
  \input{graphs/rshProm.tex}
  \vspace{-1cm}
  \caption{Promises allocated}
  \label{fig:gc-pressure}
\end{figure}
%
For an additional estimation of how much promises occur and are avoided by a
strict R, we measure the number of promises allocated in the
benchmark suite per iteration for GNU R, Ř and Ř-strict. The results are shown in
\autoref{fig:gc-pressure}. The first jump from GNU R's bytecode interpreter to
the optimizing just-in-time compiler \Rsh, leads to an \promiseAlocationReductionGnurRsh
reduction in allocations. The second step
from lazy to eager semantics leads to \promiseAlocationReductionRshStrictToZero
benchmarks not allocating any promises at all. On the remainder we see an additional
\promiseAlocationReductionRshStrict reduction.
Overal, \promiseAlocationReductionRshStrictToZero benchmarks reduce to zero
allocations, the rest reduce on average by \promiseAlocationReductionGnurRshStrict.
The lowest reduction observed is
\promiseAlocationReductionGnurRshStrictMin.
Surprisingly the number of remaining promises is
still relatively high in some cases. As far as we were able to observe, they
originate largely from two sources. One are default argument expressions, which
are still bundled in promises. \OF{which bms and how much?} The other are special forms, \ie R builtins with a custom evaluation
strategy, that are not yet natively supported in the \Rsh bytecode.

\paragraph{Discussion}

It was surprising to see that the resulting speedup of both tiers were
extremely similar, however the underlying reasons were at times very different.
Take for instance the \lstinline{Binarytrees} benchmark, which showed in both
the bytecode interpreter and the native compiler a speedup of about $1.5\times$
in the strict mode. In native the execution time decreased from 79ms to 53ms, in
the interpreter from 143ms to 97ms per iteration. However, the reasons for the
seemingly similar speedup are very different. In both tiers we observed a
proportional reduction of the time spent in tracing the heap for garbage collection,
that accounted for only about $5\%$ of the speedup. We investigated the
remaining difference using \lstinline{perf} and found that for the bytecode interpreter the overheads of
lazy evaluation in that benchmark were in promise allocation (\ie acquiring an
appropriately sized chunk of memory from the freelist) and setting up the
execution context for promise evaluation. This includes marking it as being
executed to detect recursive evaluation dependencies and calling the interpreters
main eval-loop on the code of the promise.
In the native code there is also some reduction in promise allocation and
evaluation overhead, however a significant part of the speedup is due to better
optimizations. Previously the local variables of the innermost function in
that benchmark are kept in a first-class R environment, since \Rsh does not yet
support speculative environment elision for recursive functions. But thanks to eager
evaluation of the arguments, the argument promises do not leak the environment
and therefore \Rsh is able to speculatively elide it.

\section{Robustness}

For validation, we selected 2000 dependent packages of the synthesis
corpus. They have 4.5M lines of R code and 4.7M lines of native (C, C++, and
Fortran) code. We run their examples, tests, and vignettes to exercise the
functions with signatures.

% TODO for end
% Table~\cite{tab:ten_sigs} shows ten representative signatures generated by the
% synthesis step of our experiments.
%
% \begin{table}
%   \vspace{-3mm}
%   \caption{Strictness Signatures} \label{table:ten_sigs}
%   \centering
%   \begin{tabular}{ll}
%     \toprule
%     \bf Function &\bf Strictness Signature\\
%     \hline
%     \bottomrule
%   \end{tabular}
% \end{table}

\subsection{Robustness (H2)} \label{Evaluation:Robustness}

\begin{table}
  \vspace{-3mm}
  \small
  \caption{Strictness Failure} \label{table:strictfail}
  \centering
  \begin{tabular}{lcr|lr|lr|lr|lr|l}
    \toprule
    \#&\textbf{Configuration}&\multicolumn{2}{c}{\textbf{test}}&\multicolumn{2}{c}{\textbf{vignette}}&\multicolumn{2}{c}{\textbf{example}}&\multicolumn{2}{c}{\textbf{testthat}}&\multicolumn{2}{c}{\textbf{total}}\\
    \midrule
    0&$+U+E+R$&5&2.09\%&25&10.46\%&163&68.2\%&46&19.25\%&239&0.56\%\\
    1&$+U+E-R$&4&1.71\%&24&10.26\%&162&69.23\%&44&18.8\%&234&0.55\%\\
    2&$+U-E+R$&28&1.46\%&101&5.25\%&1594&82.93\%&199&10.35\%&1922&4.51\%\\
    3&$+U-E-R$&41&0.62\%&99&1.49\%&1649&24.89\%&4836&73\%&6625&15.54\%\\
    4&$-U+E+R$&21&3.44\%&87&14.26\%&409&67.05\%&93&15.25\%&610&1.43\%\\
    5&$-U+E-R$&20&3.25\%&91&14.77\%&412&66.88\%&93&15.1\%&616&1.44\%\\
    6&$-U-E+R$&46&1.98\%&156&6.73\%&1861&80.25\%&256&11.04\%&2319&5.44\%\\
    7&$-U-E-R$&57&0.8\%&181&2.53\%&2084&29.11\%&4836&67.56\%&7158&16.79\%\\
    \bottomrule
  \end{tabular}
\end{table}

\section{Discussion}



\section{Migration Strategy}
- py2to3 does not do a good job
- hack has a simple migration tool
- scala 2 to 3 has migration tools

- If we have signatures for every test on CRAN.
-
\AG{rlang has defiintion of SEXP.}

%%\section*{Acknowledgments}
%% TODO: Thank Flip
\bibliography{bib/jv, bib/aviral, bib/ml, bib/bib}

\end{document}
