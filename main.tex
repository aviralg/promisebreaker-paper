\documentclass[screen,acmsmall]{acmart}
\settopmatter{printfolios=true,printccs=true,printacmref=true}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}   %% For author/year citations
\usepackage{mathpartir}
\usepackage[utf8]{inputenc}
\usepackage{fontenc}
\usepackage{microtype}
\usepackage{listings,array,multirow,wrapfig,xspace,booktabs,subcaption}
\usepackage{xcolor,tikz, graphicx}
\usetikzlibrary{positioning}

\newcommand{\authorcomment}[3]{\xspace\textcolor{#1}{{\bf #2} #3}\xspace} % start by defining an authorcomment

% For author notes:
%
\newcommand{\AG}[1]{\authorcomment{orange}{AG}{#1}}
\newcommand{\JV}[1]{\authorcomment{red}{JV}{#1}}

% For meta comments:
%
\newcommand{\isit}[1]{\authorcomment{cyan}{Check}{#1}}
\newcommand{\todo}[1]{\authorcomment{red}{TODO}{#1}}


\lstset{language=R}

\definecolor{LightGray}{rgb}{.92,.92,.92}
\definecolor{Gray}{rgb}{.3,.3,.3}
\definecolor{DarkGray}{rgb}{.5,.5,.5}

\lstset{ %
  columns=flexible,
  captionpos=b,
  frame=single,
  framerule=0pt,
  framexleftmargin=-1mm,
  framexrightmargin=-1mm,
  tabsize=2,
  belowskip=0pt,
  basicstyle=\small\ttfamily,
  backgroundcolor=\color{LightGray},
  emphstyle=\sffamily,
  keywordstyle=\bfseries,
  commentstyle=\color{Gray}\em,
  stringstyle=\color{Gray}
}
\lstdefinestyle{R}{ %
  language=R,
  deletekeywords={new, env, equal, c, runif, trace, args, exp, t, all, get,
    names, is, environment, class, substitute, expression, list, null, Internal,
    sample, diag, length, rep, nrow, stop, offset, pmax, Machine,
    double, parent, frame, par, methods, end, dir, apply, deparse, missing,
    plot, as, integer, character, inherits, numeric, paste, eval, quote, call,
    formula, df, log, sum, c, local, legend, file, scale, round, title, order,
    drop, which, grid, print, ncol, dim, max, format, sort, rug, matrix, start,
    unique, mean, df, attr, do, power},
  otherkeywords={},
  breaklines=true
}

\newcommand{\code}[1]{\lstinline[style=R]|#1|\xspace}
\renewcommand{\c}[1]{\lstinline[style=R]|#1|\xspace}

%%% \setcopyright{rightsretained}
%%% \acmPrice{}
%%% \acmDOI{10.1145/3360579}
%%% \acmYear{2019}
%%% \copyrightyear{2019}
%%% \acmJournal{PACMPL}
%%% \acmVolume{3}
%%% \acmNumber{OOPSLA}
%%% \acmArticle{153}
%%% \acmMonth{10}
\begin{document}
\title{Promises are made to be broken}
\subtitle{On providing strict evaluation semantics for the R language}

\author{Aviral Goel}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Ječmen}\affiliation{\institution{Czech Technical University}\country{Czechia}}
\author{Sebastián Krynski}\affiliation{\institution{Czech Technical University}\country{Czechia}}
\author{Oliver Flückiger}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Vitek}\affiliation{\institution{Czech Technical University and Northeastern University}\country{USA}}
\authorsaddresses{}
\renewcommand{\shortauthors}{Goel, Vitek}

\begin{abstract}
  Function calls in the R language do not evaluate their arguments, these are
  passed as suspended computations to the callee which will evaluate them only
  if they are needed. After 25 years of experience with the language, there are
  very few cases where delayed evaluation is being intentionally leveraged by
  programmers. Yet being lazy comes at a price in performance and complexity.
  This paper explores what would happen if the semantics of the language was
  changed to become strict-by-default and lazy-on-demand. To answer this
  question we implemented a dynamic analysis that synthesizes strictness
  signatures for functions. Given such signature, we implemented a tool that
  automatically transforms source code to enforce the signatures. We then
  performed a large scale evaluation of the robustness of the inferred
  signature. Finally we explored the impact of providing strictness signatures
  on a just-in-time compiler.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002944.10011123.10010912</concept_id>
<concept_desc>General and reference~Empirical studies</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011050.10010517</concept_id>
<concept_desc>Software and its engineering~Scripting languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011039.10011311</concept_id>
<concept_desc>Software and its engineering~Semantics</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{General and reference~Empirical studies}
\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[500]{Software and its engineering~Scripting languages}
\ccsdesc[300]{Software and its engineering~Semantics}

\keywords{R language, delayed or lazy evaluation}

\maketitle
\section{Introduction}

The R programming language is widely used in data science. Unbeknownst to many
of its end-users, function calls have a call-by-need, or lazy, semantics. In
other words the arguments of a function call are suspended computations which
are evaluated if and when they are needed. \citet{oopsla19b} provided a thorough
observational study of a corpus consisting of 16,707 packages written in R. For
the most part, the corpus appears to have been written without reliance on
laziness with the exception of code that leverages it for meta-programming.

This paper argues that laziness should be the exception in R. We propose to make
it a \emph{eager by default, lazy on demand} language by introducing strictness
annotations. The question we wish to answer is whether it is possible to switch
the semantics of a language without causing undue breakage in the legacy code
that is in daily use. This concern is relevant because, even if programmers
don't avail themselves of call-by-need, it is conceivable that their code
accidentally depends on it. A change in the order of evaluation of arguments may
introduce errors if that code was performing side effects.

\paragraph{The Case for Strictness.} Laziness is error-prone, inconsistent
and costly. The combination of delayed evaluation and side-effects in a language
without type annotations is an invitation to subtle programming errors. If a
function has multiple evaluation orders and is called with effectful arguments,
their effects will be observed to happen in various orders. Functional languages
prevent ordering issues by reflecting effects in the type system. R cannot do
this as it is dynamically typed. Instead, libraries routinely add code at the
boundaries of their API to force a single evaluation order. The design and use
of call-by-need is inconsistent because there are multiple points where
evaluation is arbitrarily forced. These include right-hand side of assignments
and function returns, neither of which is required in a lazy language.
Furthermore, to support object-oriented programming, R allows both single- and
multiple-dispatch; in order to perform dispatch, arguments must be evaluated
eagerly. Last, there are costs to lazy evaluation. Each argument must be boxed
in a data structure that holds a reference to the expression to evaluate, its
environment and the result of evaluation. Allocating and deallocating these data
structures put pressure on the memory manager. Delayed evaluation further
complicates the work of compilers for the language by hindering optimizations
and increasing the number of indirect calls.

\paragraph{The Case for Laziness.} The success of a programming language
often comes down to the strength of its ecosystem. With tens of millions of
lines of contributed library code, any change to the core semantics of the
language risks changing the behavior of some library functions. Preserving the
status quo is a pragmatic choice to protect the investment in legacy code bases.
Laziness is needed for an additional reason, it is the building block of the
meta-programming facilities of the language. Unevaluated arguments can be
coerced back to their source code, that code can be modified, and evaluated in
an environment of the programmer's choice. Meta-programming is used to extend
the language and to create embedded domain specific languages. While it is
possible to imagine using macros instead, the number of libraries that use
meta-programming is sufficiently large that it would be non-trivial to refactor
them.

\section{Background}
\subsection{Related Work}

\subsection{The R Language}

\section{Strictness Signatures for R}

\emph{Metaprogramming}

\emph{Effects}

\emph{Reflection}

\subsection{Synthesizing Signatures}

\section{Analysis Infrastructure}
In this section, we describe the analysis pipeline that \emph{(a)} profiles R
programs for laziness, \emph{(b)} extracts and analyzes strictness signatures
from the profile, and \emph{(c)} validates those signatures by eagerly forcing
function arguments. The analysis pipeline starts with setting up a Docker image
that includes all the dependencies for installing analysis code and R packages
from CRAN and Bioconductor. This provides a reliable reproducible setup across
the three machines. Next, we mirror CRAN and Bioconductor repositories and
install their R packages. This is followed by generation of execution traces
from a dynamic analyzer running inside an instrumented R virtual machine. These
traces are analyzed to generate tabular data files and strictness signatures.
Finally, the signatures are applied to client programs for validation. Our
experiments were performed on three Intel Xeon 6140, 2.30GHz machines with 72
cores and 256GB of RAM each. The pipeline is managed by a Makefile which has
rules for every step. This makes it easy to administer the experiments on
multiple machines. Whenever possible, we parallelize the steps using GNU
parallel\cite{tange2011a}.

\subsection{Synthesizing Laziness Signatures}

A function's strictness signature is a tuple $\langle p, f, s_1, ..., s_n
\rangle$, where $p$ is the package in which the function is defined, $f$ is the
function's name and $s_i$ are one based positions of arguments that can be
evaluted strictly. We synthesize strictness signatures for functions by
observing the evaluation of their arguments at runtime. For this, we use three
tools that enable us to dynamically inspect a function call's arguments.

%% R-dyntrace

First,
we use an instrumented R virtual machine, \emph{R-dyntrace} \citet{oopsla19b}
based on GNU-R version 4.0.2. The framework provides an event framework for
invoking user-defined callbacks at specific points inside the R interpreter.
\emph{R-dyntrace} supplies raw R objects to the callbacks. Extracting meaningful
information at this low level requires handling a lot of subtleties arising from
the intricacies of R's implementation and execution model. These details are
surprisingly hard to get right, even for simple progrms. The challenges are
described in detail by \cite{oopsla19b} in the design of their tracer for
collecting information about use of laziness in R programs.

%% instrumentr

To iron these wrinkles, we developed \emph{instrumentr}, an R package that
provides a layer of abstraction on top of the event framework exposed by
\emph{R-dyntrace}. \emph{instrumentr} intercepts \emph{R-dyntrace} events and
invokes callbacks registered by clients. It passes model R objects to client
callbacks by wrapping the raw R objects provided to its own callbacks registered
with \emph{R-dyntrace}. These model objects contain metadata about the raw R
object and provide a consistent API for inspecting their constituents.
\begin{itemize}
\item The object metadata keeps track of the object's unique id. This uniqueness guarantee
enables downstream client analyses to key objects by their id instead of
addresses which are not unique since they get resused by R's garbage collector.
\item The model objects are reference counted which makes it possible for a model
object to be referenced by multiple model objects with proper memory management.
A complication arises in this design when objects have cyclic references. For
example, a promise argument keeps a reference to a call object and vice-versa.
To address this, \emph{instrumentr} defines the notion of a primary owner. The
primary owner of a model object can ``kill'' the object, i.e. free up object's
internals (and decrement the references it holds to other objects) even if it is
referenced by other objects. Killing does not free up the model object's memory
or affect its metadata. This lets secondary owners access the dead object's
metadata even after the raw R object no longer exists. The ``dead'' object's
memory is finally freed when it is no longer referenced by any other object in
the system. This design insight makes it trivial to express complex object
dependencies without any memory leaks at the scale of millions of objects. This
also enables clients to query dead object's metadata if they are referenced by
model objects made available to the clients via their callbacks. This greatly
simplifies the handling of promises, first class environments and function
calls.
\item \emph{instrumentr} keeps track of logical time, from tracing entry to
tracing exit, incremented on every event. The model object's metadata keeps
track of its time of allocation and deallocation. For environments, it also
keeps track of last read and last write time. For promises, it keeps track of
force entry and force exit time. This information is used to identify non-local
reads and writes to environments. The model objects are cached in a table keyed
by the R object's address. Table entries are inserted and erased on \emph{object
  allocation and deallocation} events respectively. This prevents duplication of
model objects when the same R object is encountered on multiple events.
\item \emph{instrumentr} models the call stack. It also adds promise objects under
evaluation to the stack. This helps identify if an event, say a side-effect, is
occuring inside a promise. Furthermore, R uses \emph{longjmp} to do non-local
returns. \emph{instrumentr} exposes a deterministic behavior during such events
by artificially calling the exit callbacks of interrupted calls and promises on
the stack. This simplifies the client side tracing logic, significantly.
\item \emph{instrumentr} keeps track of environment and function names in their model
objects. Getting fully qualified function names dynamically is challenging in R
becausse packages are first class environments that are constructed piecemeal
and all functions are by default anonymous objects that may be bound to a name
in their lexical scope. \emph{instrumentr} handles this by assigning names to
environments on package load events and checking on every write if a function is
being bound to a name. Functions can be nested to arbitrary depths in which case
\emph{instrumentr} links model objects together to reflect the parent-child
relationship.
\end{itemize}
%% lazr

For extracting execution
traces, we developed \emph{lazr}, an R library which sits atop
\emph{instrumentr}. \emph{lazr} collects information about function calls,
arguments, side-effects, and reflective environment access. from the model
objects provided by the following instrumentr event: \emph{function entry and
  exit}, \emph{promise evaluation entry and exit}, \emph{variable reads and
  writes}, \emph{promise value and expression reads}, and \emph{function
  lookup}. This information is stored in compressed tabular format using R's
\emph{fst} library. Analysis scripts provided by \emph{lazr} use this data to
synthesize strictness signatures.

\subsection{Applying Strictness Signatures}

To apply a function's strictness signature, we force the corresponding
arguments on every call to that fuction. For this, we developed \emph{strictr},
an R package that adds code to force arguments at the top of a function's
definition. R allows packages to register callbacks which are invoked when a
package is loaded by the program. \emph{strictr} sets up a package load callback
for all the packages for which we generate signatures. When a program loads a
package, \emph{strictr}'s callback is invoked. \emph{strictr} reads the
signatures for functions of the loaded package from a file, and injects code in
the function's definition in accordance with the signature. The injected code
first checks for missingness and evaluates the argument only if it is supplied
by the user or has a default value. The arguments are evaluated in the order
specified by the signature. \emph{strictr} also supports nested functions by
recursively descending into the parent function's definitions until it finds the
inner function binding. Signatures are made available to \emph{strictr} as a
directory containing one file per package. Providing signatures in external
files avoids the need to modify the source code of programs. This also enables
easy experimentation with different signature configurations by providing a
different directory location.

\section{Corpus of R Programs}

-- number of R packges
-- number of programs
-- number of loc
-- number of R functions
-- number of parameters
-- number of promises
-- functions per package
-- distribution of calls
-- distribution of arguments

\section{Evaluation}

\subsection{Strictness}

\subsection{Robustness}

\section{Discussion}

\section{Conclusion}


%%\section*{Acknowledgments}
%% TODO: Thank Flip
\bibliography{bib/jv, bib/aviral}

\end{document}
