\documentclass[screen,acmsmall]{acmart}
\settopmatter{printfolios=true,printccs=true,printacmref=true}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}   %% For author/year citations
\usepackage{mathpartir}
\usepackage[utf8]{inputenc}
\usepackage{fontenc}
\usepackage{microtype}
\usepackage{listings,array,multirow,wrapfig,xspace,booktabs,subcaption}
\usepackage{xcolor,tikz, graphicx}
\usetikzlibrary{positioning}

\newcommand{\authorcomment}[3]{\xspace\textcolor{#1}{{\bf #2} #3}\xspace} % start by defining an authorcomment

% For author notes:
%
\newcommand{\AG}[1]{\authorcomment{orange}{AG}{#1}}
\newcommand{\JV}[1]{\authorcomment{red}{JV}{#1}}

% For meta comments:
%
\newcommand{\isit}[1]{\authorcomment{cyan}{Check}{#1}}
\newcommand{\todo}[1]{\authorcomment{red}{TODO}{#1}}


\lstset{language=R}

\definecolor{LightGray}{rgb}{.92,.92,.92}
\definecolor{Gray}{rgb}{.3,.3,.3}
\definecolor{DarkGray}{rgb}{.5,.5,.5}

\lstset{ %
  columns=flexible,
  captionpos=b,
  frame=single,
  framerule=0pt,
  framexleftmargin=-1mm,
  framexrightmargin=-1mm,
  tabsize=2,
  belowskip=0pt,
  basicstyle=\small\ttfamily,
  backgroundcolor=\color{LightGray},
  emphstyle=\sffamily,
  keywordstyle=\bfseries,
  commentstyle=\color{Gray}\em,
  stringstyle=\color{Gray}
}
\lstdefinestyle{R}{ %
  language=R,
  deletekeywords={new, env, equal, c, runif, trace, args, exp, t, all, get,
    names, is, environment, class, substitute, expression, list, null, Internal,
    sample, diag, length, rep, nrow, stop, offset, pmax, Machine,
    double, parent, frame, par, methods, end, dir, apply, deparse, missing,
    plot, as, integer, character, inherits, numeric, paste, eval, quote, call,
    formula, df, log, sum, c, local, legend, file, scale, round, title, order,
    drop, which, grid, print, ncol, dim, max, format, sort, rug, matrix, start,
    unique, mean, df, attr, do, power},
  otherkeywords={},
  breaklines=true
}

\newcommand{\code}[1]{\lstinline[style=R]|#1|\xspace}
\renewcommand{\c}[1]{\lstinline[style=R]|#1|\xspace}

%%% \setcopyright{rightsretained}
%%% \acmPrice{}
%%% \acmDOI{10.1145/3360579}
%%% \acmYear{2019}
%%% \copyrightyear{2019}
%%% \acmJournal{PACMPL}
%%% \acmVolume{3}
%%% \acmNumber{OOPSLA}
%%% \acmArticle{153}
%%% \acmMonth{10}
\begin{document}
\title{Promises are made to be broken}
\subtitle{On providing strict evaluation semantics for the R language}

\author{Aviral Goel}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Ječmen}\affiliation{\institution{Czech Technical University}\country{Czechia}}
\author{Sebastián Krynski}\affiliation{\institution{Czech Technical University}\country{Czechia}}
\author{Oliver Flückiger}\affiliation{\institution{Northeastern University}\country{USA}}
\author{Jan Vitek}\affiliation{\institution{Czech Technical University and Northeastern University}\country{USA}}
\authorsaddresses{}
\renewcommand{\shortauthors}{Goel, Vitek}

\begin{abstract}
  Function calls in the R language do not evaluate their arguments, these are
  passed as suspended computations to the callee which will evaluate them only
  if they are needed. After 25 years of experience with the language, there are
  very few cases where delayed evaluation is being intentionally leveraged by
  programmers. Yet being lazy comes at a price in performance and complexity.
  This paper explores what would happen if the semantics of the language was
  changed to become strict-by-default and lazy-on-demand. To answer this
  question we implemented a dynamic analysis that synthesizes strictness
  signatures for functions. Given such signature, we implemented a tool that
  automatically transforms source code to enforce the signatures. We then
  performed a large scale evaluation of the robustness of the inferred
  signature. Finally we explored the impact of providing strictness signatures
  on a just-in-time compiler.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002944.10011123.10010912</concept_id>
<concept_desc>General and reference~Empirical studies</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011050.10010517</concept_id>
<concept_desc>Software and its engineering~Scripting languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011039.10011311</concept_id>
<concept_desc>Software and its engineering~Semantics</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{General and reference~Empirical studies}
\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[500]{Software and its engineering~Scripting languages}
\ccsdesc[300]{Software and its engineering~Semantics}

\keywords{R language, delayed or lazy evaluation}

\maketitle
\section{Introduction}

The R programming language is widely used in data science. Unbeknownst to many
of its end-users, function calls have a call-by-need, or lazy, semantics. In
other words the arguments of a function call are suspended computations which
are evaluated if and when they are needed. \citet{oopsla19b} provided a thorough
observational study of a corpus consisting of 16,707 packages written in R. For
the most part, the corpus appears to have been written without reliance on
laziness with the exception of code that leverages it for meta-programming.

This paper argues that laziness should be the exception in R. We propose to make
it a \emph{eager by default, lazy on demand} language by introducing strictness
annotations. The question we wish to answer is whether it is possible to switch
the semantics of a language without causing undue breakage in the legacy code
that is in daily use. This concern is relevant because, even if programmers
don't avail themselves of call-by-need, it is conceivable that their code
accidentally depends on it. A change in the order of evaluation of arguments may
introduce errors if that code was performing side effects.

\paragraph{The Case for Strictness.} Laziness is error-prone, inconsistent
and costly. The combination of delayed evaluation and side-effects in a language
without type annotations is an invitation to subtle programming errors. If a
function has multiple evaluation orders and is called with effectful arguments,
their effects will be observed to happen in various orders. Functional languages
prevent ordering issues by reflecting effects in the type system. R cannot do
this as it is dynamically typed. Instead, libraries routinely add code at the
boundaries of their API to force a single evaluation order. The design and use
of call-by-need is inconsistent because there are multiple points where
evaluation is arbitrarily forced. These include right-hand side of assignments
and function returns, neither of which is required in a lazy language.
Furthermore, to support object-oriented programming, R allows both single- and
multiple-dispatch; in order to perform dispatch, arguments must be evaluated
eagerly. Last, there are costs to lazy evaluation. Each argument must be boxed
in a data structure that holds a reference to the expression to evaluate, its
environment and the result of evaluation. Allocating and deallocating these data
structures put pressure on the memory manager. Delayed evaluation further
complicates the work of compilers for the language by hindering optimizations
and increasing the number of indirect calls.

\paragraph{The Case for Laziness.} The success of a programming language
often comes down to the strength of its ecosystem. With tens of millions of
lines of contributed library code, any change to the core semantics of the
language risks changing the behavior of some library functions. Preserving the
status quo is a pragmatic choice to protect the investment in legacy code bases.
Laziness is needed for an additional reason, it is the building block of the
meta-programming facilities of the language. Unevaluated arguments can be
coerced back to their source code, that code can be modified, and evaluated in
an environment of the programmer's choice. Meta-programming is used to extend
the language and to create embedded domain specific languages. While it is
possible to imagine using macros instead, the number of libraries that use
meta-programming is sufficiently large that it would be non-trivial to refactor
them.

\section{Background}
\subsection{Related Work}

\subsection{The R Language}

\section{Strictness Signatures for R}

\emph{Metaprogramming}

\emph{Effects}

\emph{Reflection}

\subsection{Synthesizing Signatures}

\section{Analysis Infrastructure}

\subsection{Instrumented R}

\subsection{Lazr}

\subsection{Synthesis of Laziness Signatures}

\subsection{Strictr}

\subsection{Application of Strictness Signatures}

\section{Corpus of R Programs}

-- number of R packges
-- number of programs
-- number of loc
-- number of R functions
-- number of parameters
-- number of promises
-- functions per package
-- distribution of calls
-- distribution of arguments

\section{Evaluation}

\subsection{Strictness}

\subsection{Robustness}

\section{Discussion}

\section{Conclusion}


%%\section*{Acknowledgments}
%% TODO: Thank Flip
\bibliography{bib/jv, bib/aviral}

\end{document}
